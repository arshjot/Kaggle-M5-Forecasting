{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from tqdm import notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pickle as pkl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../../data/sales_train_validation.csv')\n",
    "sell_prices = pd.read_csv('../../data/sell_prices.csv')\n",
    "calendar = pd.read_csv('../../data/calendar.csv')\n",
    "sample_submission = pd.read_csv('../../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.date =  pd.to_datetime(calendar.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar['relative_year'] = 2016 - calendar.year\n",
    "\n",
    "# convert month, day and weekday to cyclic encodings\n",
    "calendar['month_sin'] = np.sin(2 * np.pi * calendar.month/12.0)\n",
    "calendar['month_cos'] = np.cos(2 * np.pi * calendar.month/12.0)\n",
    "calendar['day_sin'] = np.sin(2 * np.pi * calendar.date.dt.day/calendar.date.dt.days_in_month)\n",
    "calendar['day_cos'] = np.cos(2 * np.pi * calendar.date.dt.day/calendar.date.dt.days_in_month)\n",
    "calendar['weekday_sin'] = np.sin(2 * np.pi * calendar.wday/7.0)\n",
    "calendar['weekday_cos'] = np.cos(2 * np.pi * calendar.wday/7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_events = ['SuperBowl', 'ValentinesDay', 'PresidentsDay', 'StPatricksDay',\n",
    "                  'OrthodoxEaster', 'Cinco De Mayo', \"Mother's day\", 'MemorialDay',\n",
    "                  \"Father's day\", 'IndependenceDay', 'Eid al-Fitr', 'LaborDay',\n",
    "                  'ColumbusDay', 'Halloween', 'EidAlAdha', 'VeteransDay',\n",
    "                  'Thanksgiving', 'Christmas', 'NewYear', 'OrthodoxChristmas', \n",
    "                  'MartinLutherKingDay', 'Easter']\n",
    "multi_day_events = ['LentStart', 'LentWeek2', 'Purim End', 'Pesach End',\n",
    "                    'NBAFinalsStart', 'NBAFinalsEnd', 'Ramadan starts', 'Chanukah End']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate columns for each event\n",
    "for event in one_day_events:\n",
    "    calendar[event] = [1 if val == event else 0 for val in calendar.event_name_1]\n",
    "    calendar.loc[calendar.event_name_2 == event, event] = 1\n",
    "    \n",
    "calendar['Lent'] = [1 if val == 'LentStart' else 0 for val in calendar.event_name_1]\n",
    "calendar.loc[calendar.event_name_2 == 'LentStart', 'Lent'] = 1\n",
    "calendar['Purim'] = [1 if val == 'Purim End' else 0 for val in calendar.event_name_1]\n",
    "calendar.loc[calendar.event_name_2 == 'Purim End', 'Purim'] = 1\n",
    "calendar['Pesach'] = [1 if val == 'Pesach End' else 0 for val in calendar.event_name_1]\n",
    "calendar.loc[calendar.event_name_2 == 'Pesach End', 'Pesach'] = 1\n",
    "calendar['Ramadan'] = [1 if val == 'Ramadan starts' else 0 for val in calendar.event_name_1]\n",
    "calendar.loc[calendar.event_name_2 == 'Ramadan starts', 'Ramadan'] = 1\n",
    "calendar['Chanukah'] = [1 if val == 'Chanukah End' else 0 for val in calendar.event_name_1]\n",
    "calendar.loc[calendar.event_name_2 == 'Chanukah End', 'Chanukah'] = 1\n",
    "\n",
    "calendar['NBAFinals'] = [1 if (val == 'NBAFinalsStart') else None for val in calendar.event_name_1]\n",
    "calendar.loc[(calendar.event_name_2 == 'NBAFinalsStart'), 'NBAFinals'] = 1\n",
    "calendar.loc[\n",
    "    (calendar.event_name_1 == 'NBAFinalsEnd') | (calendar.event_name_2 == 'NBAFinalsEnd'), 'NBAFinals'] = 0\n",
    "\n",
    "\n",
    "## for multi-day events, fill value as 1 from start to end\n",
    "# Lent ends approx 6 weeks from the start\n",
    "calendar['Lent'] = calendar['Lent'].rolling(min_periods=1, window=7*6).sum()\n",
    "# Purim lasts just 2 days\n",
    "calendar['Purim'] = calendar['Purim'].shift(-1).rolling(min_periods=1, window=2).sum()\n",
    "# Purim usually lasts for 9 days\n",
    "calendar['Pesach'] = calendar['Pesach'].shift(-8).rolling(min_periods=1, window=9).sum()\n",
    "# both start and end dates for NBA Finals have been given\n",
    "calendar['NBAFinals'] = calendar['NBAFinals'].fillna(method='ffill').fillna(0)\n",
    "calendar.loc[\n",
    "    (calendar.event_name_1 == 'NBAFinalsEnd') | (calendar.event_name_2 == 'NBAFinalsEnd'), 'NBAFinals'] = 1\n",
    "# Ramadan ends approx 30 days from the start\n",
    "calendar['Ramadan'] = calendar['Ramadan'].rolling(min_periods=1, window=30).sum()\n",
    "# Chanukah lasts for 9 days\n",
    "calendar['Chanukah'] = calendar['Chanukah'].shift(-8).rolling(min_periods=1, window=9).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_df = calendar[['wm_yr_wk', 'd', 'snap_CA', 'snap_TX', 'snap_WI', 'relative_year',\n",
    "                        'month_sin', 'month_cos', 'day_sin', 'day_cos', 'weekday_sin', 'weekday_cos',\n",
    "                        'SuperBowl', 'ValentinesDay', 'PresidentsDay', 'StPatricksDay', 'OrthodoxEaster',\n",
    "                        'Cinco De Mayo', \"Mother's day\", 'MemorialDay', \"Father's day\", 'IndependenceDay',\n",
    "                        'Eid al-Fitr', 'LaborDay', 'ColumbusDay', 'Halloween', 'EidAlAdha', 'VeteransDay',\n",
    "                        'Thanksgiving', 'Christmas', 'NewYear', 'OrthodoxChristmas', 'MartinLutherKingDay',\n",
    "                        'Easter', 'Lent', 'Purim', 'Pesach', 'Ramadan', 'Chanukah', 'NBAFinals']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all dfs, keep calender_df features separate and just concat them for each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.id = train_data.id.str[:-11]\n",
    "sell_prices['id'] = sell_prices['item_id'] + '_' + sell_prices['store_id']\n",
    "\n",
    "# add empty columns for future data\n",
    "train_data = pd.concat([train_data, pd.DataFrame(columns=['d_'+str(i) for i in range(1914, 1970)])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode categorical features using either one-hot or label encoding (for embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = ['cat_id', 'state_id'] \n",
    "label = ['item_id', 'dept_id', 'store_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[[str(i)+'_enc' for i in one_hot]] = train_data[one_hot]\n",
    "one_hot_encoder = ce.OneHotEncoder(cols=[str(i)+'_enc' for i in one_hot], use_cat_names=True)\n",
    "one_hot_encoder.fit(train_data)\n",
    "train_data = one_hot_encoder.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[[str(i)+'_enc' for i in label]] = train_data[label]\n",
    "label_encoder = ce.OrdinalEncoder(cols=[str(i)+'_enc' for i in label])\n",
    "label_encoder.fit(train_data)\n",
    "train_data = label_encoder.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substract one from label encoded as pytorch uses 0-indexing\n",
    "for col in [str(i)+'_enc' for i in label]:\n",
    "    train_data[col] = train_data[col] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape, change dtypes and add previous day sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsh/venvs/torch/lib/python3.7/site-packages/pandas/core/frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.melt(train_data, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',\n",
    "                                      'cat_id_enc_HOBBIES', 'cat_id_enc_HOUSEHOLD', 'cat_id_enc_FOODS',\n",
    "                                       'state_id_enc_CA', 'state_id_enc_TX', 'state_id_enc_WI',\n",
    "                                      'item_id_enc', 'dept_id_enc', 'store_id_enc'],\n",
    "                  var_name='d', value_vars=['d_'+str(i) for i in range(1, 1970)], value_name='sales')\n",
    "\n",
    "# change dtypes to reduce memory usage\n",
    "data_df[['sales']] = data_df[['sales']].fillna(-1).astype(np.int16)  # fill future sales as -1\n",
    "calendar_df[one_day_events + ['Lent', 'Purim', 'Pesach', 'Ramadan', 'Chanukah', 'NBAFinals', \n",
    "                              'snap_CA', 'snap_TX', 'snap_WI', 'relative_year']] = calendar_df[\n",
    "    one_day_events + ['Lent', 'Purim', 'Pesach', 'Ramadan', 'Chanukah', 'NBAFinals',\n",
    "                     'snap_CA', 'snap_TX', 'snap_WI', 'relative_year']].astype(np.int8)\n",
    "data_df[['cat_id_enc_HOBBIES', 'cat_id_enc_HOUSEHOLD', 'cat_id_enc_FOODS',\n",
    "         'state_id_enc_CA', 'state_id_enc_TX', 'state_id_enc_WI']] = data_df[\n",
    "    ['cat_id_enc_HOBBIES', 'cat_id_enc_HOUSEHOLD', 'cat_id_enc_FOODS',\n",
    "     'state_id_enc_CA', 'state_id_enc_TX', 'state_id_enc_WI']].astype(np.int8)\n",
    "data_df[['item_id_enc', 'dept_id_enc', 'store_id_enc']] = data_df[\n",
    "    ['item_id_enc', 'dept_id_enc', 'store_id_enc']].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.merge(right=calendar_df[['d', 'wm_yr_wk']], on=['d'], how='left')\n",
    "data_df = data_df.merge(right=sell_prices[['id', 'wm_yr_wk', 'sell_price']], on=['id', 'wm_yr_wk'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.sell_price = data_df.sell_price.fillna(0.0)\n",
    "data_df['prev_day_sales'] = data_df.groupby(['id'])['sales'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove data for d_1\n",
    "data_df = data_df.dropna()\n",
    "calendar_df = calendar_df[calendar_df.d != 'd_1']\n",
    "\n",
    "# change dtypes\n",
    "data_df[['prev_day_sales']] = data_df[['prev_day_sales']].astype(np.int16)\n",
    "data_df[['sell_price']] = data_df[['sell_price']].astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add previous day totals of aggregated series as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total\n",
    "data_df = data_df.merge(right=\n",
    "                        data_df.groupby(['d'])[['prev_day_sales']].sum().astype(\n",
    "                            np.int32).add_suffix('_all').reset_index(),\n",
    "                        on=['d'], how='left')\n",
    "# category level\n",
    "data_df = data_df.merge(right=\n",
    "                        data_df.groupby(['d', 'cat_id'])[['prev_day_sales']].sum().astype(\n",
    "                            np.int32).reset_index().pivot(\n",
    "                            index='d', columns='cat_id', values='prev_day_sales').add_prefix('prev_d_cat_'),\n",
    "                        on=['d'], how='left')\n",
    "# state level\n",
    "data_df = data_df.merge(right=\n",
    "                        data_df.groupby(['d', 'state_id'])[['prev_day_sales']].sum().astype(\n",
    "                            np.int32).reset_index().pivot(\n",
    "                            index='d', columns='state_id', values='prev_day_sales').add_prefix('prev_d_state_'),\n",
    "                        on=['d'], how='left')\n",
    "# store level\n",
    "data_df = data_df.merge(right=\n",
    "                        data_df.groupby(['d', 'store_id'])[['prev_day_sales']].sum().astype(\n",
    "                            np.int32).reset_index().pivot(\n",
    "                            index='d', columns='store_id', values='prev_day_sales').add_prefix('prev_d_store_'),\n",
    "                        on=['d'], how='left')\n",
    "# department level\n",
    "data_df = data_df.merge(right=\n",
    "                        data_df.groupby(['d', 'dept_id'])[['prev_day_sales']].sum().astype(\n",
    "                            np.int32).reset_index().pivot(\n",
    "                            index='d', columns='dept_id', values='prev_day_sales').add_prefix('prev_d_dept_'),\n",
    "                        on=['d'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3a972267a3b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# remove category columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wm_yr_wk'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dept_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_df' is not defined"
     ]
    }
   ],
   "source": [
    "# remove category columns\n",
    "del data_df['wm_yr_wk']\n",
    "del data_df['item_id']\n",
    "del data_df['dept_id']\n",
    "del data_df['cat_id']\n",
    "del data_df['store_id']\n",
    "del data_df['state_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = data_df.id.nunique()\n",
    "num_timesteps = data_df.d.nunique()\n",
    "data_df = data_df.set_index(['id', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_feats = ['sell_price', 'cat_id_enc_HOBBIES', 'cat_id_enc_HOUSEHOLD', 'cat_id_enc_FOODS', 'state_id_enc_CA',\n",
    "                 'state_id_enc_TX', 'state_id_enc_WI', 'item_id_enc', 'dept_id_enc', 'store_id_enc']\n",
    "enc_only_feats = data_df.columns.difference(['sales', 'sell_price', 'prev_day_sales'] + enc_dec_feats)\n",
    "\n",
    "sales_data_index = data_df.index\n",
    "Y = data_df.sales.values.reshape(num_timesteps, num_samples).T\n",
    "\n",
    "X_enc_only_feats = np.array(data_df[enc_only_feats]).reshape(num_timesteps, num_samples, -1)\n",
    "gc.collect()\n",
    "\n",
    "X_enc_dec_feats = np.array(data_df[enc_dec_feats]).reshape(num_timesteps, num_samples, -1)\n",
    "\n",
    "X_prev_day_sales = data_df.prev_day_sales.values.reshape(num_timesteps, num_samples)\n",
    "\n",
    "calendar_index = calendar_df.d\n",
    "X_calendar = np.array(calendar_df.iloc[:, 2:])\n",
    "X_calendar_cols = list(calendar_df.columns[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dict = {'sales_data_index' : sales_data_index, 'calendar_index' : calendar_index, \n",
    "#              'X_prev_day_sales' : X_prev_day_sales, \n",
    "#              'X_enc_only_feats': X_enc_only_feats, 'X_enc_dec_feats' : X_enc_dec_feats,\n",
    "#              'enc_dec_feat_names': enc_dec_feats, 'enc_only_feat_names': enc_only_feats,\n",
    "#              'X_calendar' : X_calendar, 'X_calendar_cols' : X_calendar_cols, \n",
    "#              'Y' : Y,\n",
    "#             'one_hot_encoder': one_hot_encoder, 'label_encoder': label_encoder}\n",
    "\n",
    "# # pickle data\n",
    "# with open('../data/data.pickle', 'wb') as f:\n",
    "#     pkl.dump(data_dict, f, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data.pickle', 'rb') as f:\n",
    "    data_dict = pkl.load(f)\n",
    "    \n",
    "# sales_data_index = data_dict['sales_data_index']\n",
    "calendar_index = data_dict['calendar_index']\n",
    "X_prev_day_sales = data_dict['X_prev_day_sales']\n",
    "X_enc_only_feats = data_dict['X_enc_only_feats']\n",
    "X_enc_dec_feats = data_dict['X_enc_dec_feats']\n",
    "X_calendar = data_dict['X_calendar']\n",
    "X_calendar_cols = data_dict['X_calendar_cols']\n",
    "Y = data_dict['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.utils.data\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset (Input Pipeline)\n",
    "class CustomDataset(data_utils.Dataset):\n",
    "    '''\n",
    "    Custom dataset\n",
    "    \n",
    "    Let:\n",
    "    training period timesteps = [0, N]\n",
    "    prediction period timesteps = [N+1, N+P]\n",
    "    \n",
    "    Arguments:\n",
    "    X_prev_day_sales : previous day sales for training period ([0, N])\n",
    "    X_enc_only_feats : aggregated series' previous day sales for training period ([0, N])\n",
    "    X_enc_dec_feats : sell price and categorical features for training and prediction period ([0, N+P])\n",
    "    X_calendar : calendar features for training and prediction period ([0, N+P])\n",
    "    X_last_day_sales : the actual sales for the day before the start of the prediction period (for timestep N)\n",
    "                       (this will serve as the first timestep's input for the decoder)\n",
    "    Y : actual sales, denoting targets for prediction period ([N+1, N+P])\n",
    "    \n",
    "    Returns:\n",
    "    List of torch arrays:\n",
    "    x_enc: concatenated encoder features (except embedding)\n",
    "    x_enc_emb: concatenated encoder embedding features\n",
    "    x_dec: concatenated decoder features (except embedding)\n",
    "    x_dec_emb: concatenated decoder embedding features\n",
    "    x_last_day_sales: the actual sales for the day before the start of the prediction period\n",
    "    y: targets (only in training phase)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, X_prev_day_sales, X_enc_only_feats,\n",
    "                 X_enc_dec_feats, X_calendar, X_last_day_sales, \n",
    "                 Y=None, transform=None):\n",
    "        self.X_prev_day_sales = X_prev_day_sales\n",
    "        self.X_enc_only_feats = X_enc_only_feats\n",
    "        self.X_enc_dec_feats = X_enc_dec_feats\n",
    "        self.X_calendar = X_calendar\n",
    "        self.X_last_day_sales = X_last_day_sales\n",
    "        \n",
    "        if Y is not None:\n",
    "            self.Y = torch.from_numpy(Y).float()\n",
    "        else:\n",
    "            self.Y = None\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X_prev_day_sales.shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc_timesteps = self.X_prev_day_sales.shape[0]\n",
    "        dec_timesteps = self.X_enc_dec_feats.shape[0] - enc_timesteps\n",
    "        num_embedding = 3\n",
    "        \n",
    "        # input data for encoder\n",
    "        x_enc_dec_feats_enc = self.X_enc_dec_feats[:enc_timesteps, idx, :-num_embedding]\n",
    "#         x_enc_only_feats = self.X_enc_only_feats[:, idx, :].reshape(enc_timesteps, -1)\n",
    "        x_prev_day_sales_enc = self.X_prev_day_sales[:, idx].reshape(-1, 1)\n",
    "        x_calendar_enc = self.X_calendar[:enc_timesteps, :]\n",
    "#         x_enc = np.concatenate([x_enc_dec_feats_enc, x_calendar_enc, \n",
    "#                                 x_prev_day_sales_enc, x_enc_only_feats], axis=1)\n",
    "        x_enc = np.concatenate([x_enc_dec_feats_enc, x_calendar_enc, \n",
    "                                x_prev_day_sales_enc], axis=1)\n",
    "        x_enc_emb = self.X_enc_dec_feats[:enc_timesteps, idx, -num_embedding:].reshape(enc_timesteps, -1)\n",
    "        \n",
    "        # input data for decoder\n",
    "        x_enc_dec_feats_dec = self.X_enc_dec_feats[enc_timesteps:, idx, :-num_embedding].reshape(dec_timesteps, -1)\n",
    "        x_calendar_dec = self.X_calendar[enc_timesteps:, :]\n",
    "        x_last_day_sales = self.X_last_day_sales[idx].reshape(-1)\n",
    "        x_dec = np.concatenate([x_enc_dec_feats_dec, x_calendar_dec], axis=1)\n",
    "        x_dec_emb = self.X_enc_dec_feats[enc_timesteps:, idx, -num_embedding:].reshape(dec_timesteps, -1)\n",
    "        \n",
    "        if self.Y is None:\n",
    "            return [torch.from_numpy(x_enc).float(), torch.from_numpy(x_enc_emb).long(), \n",
    "                    torch.from_numpy(x_dec).float(), torch.from_numpy(x_dec_emb).long(),\n",
    "                    torch.from_numpy(x_last_day_sales).float()]\n",
    "            \n",
    "        return [torch.from_numpy(x_enc).float(), torch.from_numpy(x_enc_emb).long(),\n",
    "                torch.from_numpy(x_dec).float(), torch.from_numpy(x_dec_emb).long(),\n",
    "                torch.from_numpy(x_last_day_sales).float(), self.Y[idx, :], idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_b = 1969 - 1 - (28*4)\n",
    "train_t_e = 1969 - 1 - (28*3)\n",
    "val_t_b = 1969 - 1 - (28*3)\n",
    "val_t_e = 1969 - 1 - (28*2)\n",
    "test_t_b = 1969 - 1 - (28*2)\n",
    "test_t_e = 1969 - 1 - (28*1)\n",
    "\n",
    "train_dataset = CustomDataset(X_prev_day_sales[:train_t_b], X_enc_only_feats[:train_t_b],\n",
    "                              X_enc_dec_feats[:train_t_e],\n",
    "                              X_calendar[:train_t_e], X_prev_day_sales[train_t_b], Y=Y[:, train_t_b:train_t_e])\n",
    "val_dataset = CustomDataset(X_prev_day_sales[:val_t_b], X_enc_only_feats[:val_t_b],\n",
    "                            X_enc_dec_feats[:val_t_e],\n",
    "                            X_calendar[:val_t_e], X_prev_day_sales[val_t_b], Y=Y[:, val_t_b:val_t_e])\n",
    "test_dataset = CustomDataset(X_prev_day_sales[:test_t_b], X_enc_only_feats[:test_t_b],\n",
    "                             X_enc_dec_feats[:test_t_e],\n",
    "                             X_calendar[:test_t_e], X_prev_day_sales[test_t_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, \n",
    "                                           num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([28710,  3575,  8909,  3538,  7421,  9419, 29665,  7921,  8058,  9285,\n",
      "        26566, 18354, 20411, 23149, 11088,  8717, 22808,  2740,  3124,  5884,\n",
      "        21378, 16800, 20563, 15946, 10654, 22140, 23057, 15931, 16629, 16405,\n",
      "        11249, 23634,  6815, 19548, 24216, 15552,  7532, 16035, 11319, 26319,\n",
      "        29052, 14228, 14965, 18714,  6420,  1459, 24616, 19354, 20392, 14465,\n",
      "        12952, 13947, 23104,  7642,  9589, 10448, 10891, 15259, 19232,  2145,\n",
      "        30094, 26706, 23143, 19687])\n",
      "tensor([21188,  3638, 18763, 11526, 25568,  7049, 26158, 29471, 23072, 21557,\n",
      "         9777, 25825,   345,  8088, 14468,  1562, 18542,   369,  5419, 18385,\n",
      "        15518, 10915,  8263, 20453, 27948,  7152, 30264,   673, 14495, 28839,\n",
      "         8506, 14158,  9790,  4986, 14338, 18162,  6107, 25589, 14163,  8764,\n",
      "        14406, 20975,  7472,  2701, 20491, 29328,  6948, 25596, 23846,  3624,\n",
      "          826, 16951,  1956, 13101,  4615,  9803, 15188, 13939, 17148,   508,\n",
      "         8533, 12975,  1792,  4638])\n",
      "tensor([18518, 12153, 12148, 13646, 25238, 19913, 24162, 26134,  6933,  5153,\n",
      "        18502,  4122, 13011, 12138, 25597, 11069, 22464, 21116,  4078, 19563,\n",
      "        27505, 10471,  2455, 18790, 27063, 16382, 26069, 10782, 17477, 10474,\n",
      "        19673, 24850, 25253, 21802, 30105,  2474, 17838,  4575, 25748, 18375,\n",
      "        24456, 13227,  1065, 14178, 27026,  8012, 15510,  4238, 16388, 23751,\n",
      "         2439, 12861, 13683, 28741,   395,  2886, 20228,  8355, 25410,  9310,\n",
      "        24301, 15252, 19899, 19975])\n",
      "tensor([29794,  5474, 25804,  3113,  2672, 22346,  9193,  6750, 23163, 17577,\n",
      "        13562,  1490, 21387, 26585, 16024, 28033,   459, 23323, 27998, 14050,\n",
      "        28987, 29425, 13402, 18361, 22933, 28360, 26659,  3366, 17744, 21106,\n",
      "        10246, 16181, 17779, 20419,  4619, 13081, 26141, 24405, 19648, 14814,\n",
      "        29675, 27497,  9956, 20144, 30341,  7475,   408, 21825,  3430,   212,\n",
      "        12730, 13662,  8900, 27342,  7838, 10077, 24170, 11198, 24606,  8605,\n",
      "          713, 22161,  3531, 29948])\n",
      "tensor([ 8374, 22958, 25306, 24655, 10858, 26653,  1865,  1991, 22492, 16801,\n",
      "         9009, 19406,  8286, 26102, 21546, 24155, 16799,  3947, 14876,  6720,\n",
      "        15702,   839, 13523, 28944, 15001,  9974,  4336, 29744, 26461, 11248,\n",
      "        13249,  7824,   937, 11827, 18196,  2350, 27661, 16757, 17832, 11806,\n",
      "         2948, 28437,  4249, 18462, 29627,  9714, 25620, 24895, 20806, 21013,\n",
      "        25414, 29680, 24773, 13093, 24746, 16473,  2884,  3707, 15175, 17376,\n",
      "         7803, 25852, 29731, 12285])\n",
      "tensor([  491,  3248,  4225, 21313,  9175, 12323, 12120,  5097,  4260, 22591,\n",
      "        10747, 10274, 12603, 17012,  6157, 22735, 23270, 19632, 21208, 18804,\n",
      "        20980,  8527, 20686, 18101, 21315,  9395,  9759,  6768, 14977, 21892,\n",
      "        15870, 16413,  5189, 26640, 17510,  8561, 29169, 27134,   706, 17979,\n",
      "        14841, 21401, 12481,  9085,  5739,  3620, 20094, 11927, 30106,  7332,\n",
      "        16910,   861,  2358, 19968,  2811, 20106,  9021, 10721, 26289, 21142,\n",
      "        29807, 28551, 23199,  2924])\n",
      "tensor([ 8127,  5915, 18420,  9584,  6382,  8728, 21421, 21153, 20359,  7868,\n",
      "        25362, 29991,  2835, 16916, 17893,    10, 14411, 17225, 27275, 29015,\n",
      "        26584,  5615,  7070, 22815, 28614,  5266,  4606, 22380, 11371, 16576,\n",
      "         4025,  6650, 25679, 12896, 26195,  2025, 16098, 19909, 16748, 30343,\n",
      "        15265,  8011, 27478, 25249, 22095, 16825, 12967, 23957,  3975, 29497,\n",
      "         3123, 10929, 25277, 28304,  5411, 13498, 11770,  1646, 23412,  1040,\n",
      "        14680,  8862, 15915,  1192])\n",
      "tensor([   27,  5093,  5614,  2448,  7517,  6173, 28766, 25186, 17501, 28216,\n",
      "        16904, 27043, 20894,  4461,  6322, 10456, 27485, 22358, 27128,  4967,\n",
      "        24054, 18175,  5736, 10852,  2634, 15730,  6649, 15782, 14439, 15526,\n",
      "        25502,  1692,  7918, 11619, 14655, 17176, 29460, 16708, 27315, 29849,\n",
      "        27723, 16083, 14994, 16359,  9223, 10841, 23639,  9373, 22862,  9743,\n",
      "        11461, 10653, 21734, 22304,  6860, 25963, 14174, 15864, 26416,  1528,\n",
      "         5829, 23944, 14682, 20670])\n",
      "tensor([13659, 10082, 25946, 18083,  3752, 19519, 26714, 28160, 22922, 30313,\n",
      "         5587,  3045, 30025, 22637, 21368, 12169, 28267, 10160, 12093,   484,\n",
      "        15642, 20327, 20422, 24053, 11370, 23551,  1766,  8156,  9241, 27116,\n",
      "        24782, 27973, 28714, 16746, 24012, 27694, 16591, 21202,  1176, 17587,\n",
      "         3523,  9402, 23420, 12149, 24384, 10525, 26715,  7636, 26251, 29282,\n",
      "        15414, 25665, 13583,  3547, 10593, 13660, 12888, 13990,  9498, 13650,\n",
      "        15955, 27563, 18624, 24604])\n",
      "tensor([  890, 26157, 28026, 19545,  4679, 18574, 15019,  3106, 21910, 14932,\n",
      "        21815,  8643, 20645,  2131, 12656, 18754, 13554, 16657, 14883, 12978,\n",
      "        29341, 23446,   987,  9260, 14345, 18293,  4813,  1567,  3774,  5998,\n",
      "        18005,  4298,  4090,  4451,  8481, 15868,  2134, 28929, 22443, 13701,\n",
      "        10973, 30327,  9508, 23489, 17474,  5513, 12228,  8868, 22606, 19122,\n",
      "         1099,  6438,  9812, 22997, 24992,  2122, 26382, 12063, 11984, 24239,\n",
      "        17745, 22392, 24536, 26680])\n",
      "tensor([21848, 12475, 28579, 17364, 15532, 22300, 20470, 24936,    15,   329,\n",
      "        25014,  7773, 22856, 27239,  1773, 13019, 23003,  3469,  5131, 13669,\n",
      "        21060,  7558,  5703, 23351, 13841,  3070, 23389,  9815, 10112, 19329,\n",
      "        26847,  5638,  3675,  3762, 13205, 10447, 26902, 21573, 20517, 23872,\n",
      "        10755, 18273, 18012, 10278, 24926,  8530, 26993,  8596, 16010, 14865,\n",
      "        19943, 20131, 27945, 22972, 18885, 26168, 23210,  4220, 23101, 30023,\n",
      "        10268, 25245,  9953,  5280])\n",
      "tensor([ 9011, 18403, 20351,  6662, 18235, 23379, 11597,  6683, 22321, 29857,\n",
      "        29000,  7310, 23667, 29175,  3287, 11112, 22039,  4610, 26005, 15187,\n",
      "        17759,  9641, 21866,  3487, 20501, 29398, 15338, 17279, 24409, 18114,\n",
      "        24331, 23921,  4959, 23773, 17981, 28045, 18783, 29895, 22923,  8727,\n",
      "        16210, 28468, 24900, 12490, 16002,  6222,  5119,  8117, 14202, 24321,\n",
      "         9412,  3526, 19557,   869,  5594,  9924, 15194,  7616, 10746, 21379,\n",
      "        20869, 17383, 17565,  2650])\n",
      "tensor([14332, 13195,  8860, 28555,  8051,  4918, 25342,  6139, 22783,   663,\n",
      "         3933,  2286, 19040, 10338, 19231,  3257, 25101,  1553, 29941, 14306,\n",
      "        13332,  4698, 10954, 24931, 14243, 10041, 24529, 19781, 14577,  3720,\n",
      "        25079, 16185,  4345,  6147, 11555, 17487, 14534, 18359, 11486,  3209,\n",
      "        24494, 22302,  4500, 20544,  6631, 10298, 27800, 28244, 11918, 21518,\n",
      "        13016, 24363, 11787, 21437,  7378,  9038, 16225,     9, 14409,  7497,\n",
      "        14800, 16362,  1008, 16401])\n",
      "tensor([14931,  8360,  6954, 14604,  7525, 21839, 27949,  5106,  2236, 19862,\n",
      "        26782, 12556, 28279, 20478, 22457, 30375, 16668, 29745,  9850, 28205,\n",
      "         3629,  4932, 25139, 10366, 10245, 14111,  8343,  4707, 15934, 21276,\n",
      "        18996,  5192, 13071, 22123,  7657, 30301, 22081, 24702, 28230, 22548,\n",
      "        30410,  9339, 15625,  7935,  7859, 19275, 27159,  1583,  8778, 28450,\n",
      "        21629, 13953, 12947, 20983, 25027, 15890,  3017, 20108, 13887, 23094,\n",
      "         3657,  3403, 18171, 22372])\n",
      "tensor([29708,  5321, 19220,  3284, 28140,  6245, 29396, 28795, 27610, 12300,\n",
      "        13723, 22398, 24035,  7780, 21972,  4852, 24486, 24117, 12543, 24981,\n",
      "         1101, 23889, 15372, 23688, 25937, 29899, 26506, 19444, 20296, 17098,\n",
      "        11492, 26332, 23047, 19300, 28509, 14765,  3929,  7836, 27750, 24272,\n",
      "         7697, 10132,  1241,  9863, 17843, 13671, 27649, 19109,  8995, 29790,\n",
      "        25534, 26709, 21298,  3966, 27682, 11298, 26159, 16127,  5996, 16578,\n",
      "        22007, 15254, 11528, 22676])\n",
      "tensor([12113,   481,  6707, 11454, 21109,  4562, 16429, 17695, 14349,  9739,\n",
      "        24236,  1488,  1918, 26153, 14787, 20991, 14584, 29210,  9600, 26944,\n",
      "        13176,  2780, 14599, 13726, 29019,  7401,  2303, 20181,  3073, 15996,\n",
      "         1433,  5636, 23048,  5356, 28299, 10255, 23724, 18046, 28957, 17954,\n",
      "        21483, 28630,   771, 18960, 22212,  5961,  1505, 26565, 25727,  3151,\n",
      "         2849, 29518, 22646,  5772,   315, 26003, 11996, 10161,  4068, 24560,\n",
      "        14708, 21316, 21362, 16587])\n",
      "tensor([ 8372, 28559, 22395, 27753, 16738,  6776, 27288, 18181, 16268, 11933,\n",
      "         8577, 19207,  7633, 15436,  5528, 27032, 21352, 25067,  6273,  8486,\n",
      "        26990, 12422, 24435,  2325,  9574,  9132, 19582, 10558,  9020, 25200,\n",
      "        29415, 19872, 13782, 15701, 18819, 29496,  8368,  3101,  4187, 25450,\n",
      "        21777, 21699,  9802, 21105,  2917, 18220, 26651, 26949, 24643, 12319,\n",
      "        15954, 14146, 11694,  1650, 14322,  2848,   939,  7389, 11828, 23955,\n",
      "        13868, 16332,  7004, 22887])\n",
      "tensor([ 1785,  8655, 19380,  5420, 27028, 13964, 11912, 29733,  4824, 28852,\n",
      "         4206,   263, 18577, 19163, 25228, 11773, 12302, 14289, 14789, 12873,\n",
      "        27675, 23374,  3673,  7577, 10776, 25021,  1709, 16718, 24145,  4713,\n",
      "        16981,  1965, 27872, 13804, 16542, 30198, 18065,  6944, 16191, 23017,\n",
      "         3967,  9816, 26288, 21578, 21016, 18707,  2702,  2943, 19830,  1970,\n",
      "        22473, 26057, 18750, 28127, 18644, 11124,  5576, 24682,  6571, 18206,\n",
      "        12364,  7674,  5258,  5523])\n",
      "tensor([22074, 13676, 18538,  5662, 18699, 12606,  5582,   343, 17202, 29860,\n",
      "        22491,   688, 18663,  7407,   128,  6851,  5503, 25419, 26935, 12398,\n",
      "        10579, 24816,  6260, 23249,  6913, 13661,  5543, 20653,  6822,  4974,\n",
      "          135, 22755, 27498,  1838, 29667, 12335, 23636, 10225, 11150, 18793,\n",
      "        28751,  8459, 19308, 30064, 18765, 19222,  7930, 13137,  4701, 23660,\n",
      "        11397,  5172,   655, 25515, 17709,  7820,  1765,  3797, 20853, 16834,\n",
      "        19252, 13316,  3701, 12660])\n",
      "tensor([20339, 24495, 10691, 13373, 22431,  5403,  7756, 20317, 27598, 13118,\n",
      "         5742, 11917, 17772, 11905, 29289, 23857,  5433, 13667, 14432,  6575,\n",
      "        17094, 23353,  8606, 20935, 20205, 23387, 23378, 22387, 24819,  1975,\n",
      "        15695, 18862, 13952, 21094, 15489, 25126, 29049, 23111, 24952, 20163,\n",
      "        21741,   920,  1147, 27464, 10028,  8204,  4894,  2197, 20772, 13931,\n",
      "        18852,  1398, 24930, 19641,   251,  1313,  3069, 16869,  3264,  1884,\n",
      "          325, 21603, 24851, 10433])\n",
      "tensor([ 3328, 16806,  8461,  4754, 12263, 24732,  1451, 22764, 24724, 25035,\n",
      "        18517, 15555, 23406,  2263, 11715, 19291,  6663,  4665, 20101,  4123,\n",
      "        24894, 29154,  5632,   226, 25882, 12997, 17917, 23422,  3522, 27126,\n",
      "         9901, 30436,  9277, 27789,  7132, 21763, 20807,  8644, 13230, 17310,\n",
      "        28547,  5026, 15986,   965, 22790, 24058, 15910, 30288, 29771,  6003,\n",
      "         9729,  4938,  2719, 30312, 24027,  2372, 16893, 26592, 11310, 21420,\n",
      "         8222, 29050, 24845, 20752])\n",
      "tensor([ 1137,  8378, 24892,  5037, 16524, 28805, 12685,  6163, 25941,  8412,\n",
      "        11637, 29551, 24134, 29413, 11178,  2162,   311, 14860,  1190,  4888,\n",
      "         6002, 18213, 28291,  5751, 22536, 24761,   732, 27548, 12609,  9375,\n",
      "        16789, 14541, 24364, 25003, 26716,   407,   666,  9214, 29462, 29891,\n",
      "        28189, 18666,  2783, 28798, 24594, 12048,  3807, 26088, 26773, 23410,\n",
      "        29784,  9917, 23022, 17482,  5472, 21830, 20798, 25786, 15952,  3600,\n",
      "        14728, 18853, 28763, 20662])\n",
      "tensor([22555, 15828, 11830,  6311,  5230, 28427, 23519, 16943, 28122, 25294,\n",
      "        27556, 22413,  2465,  4349, 10683, 28098, 28077,  2368, 11295, 14204,\n",
      "        20293, 18745,  4843,  9249,  2890, 16751, 24180, 19806, 13261,  8744,\n",
      "         2820, 13633, 16130, 29561, 13448,  8116, 18399, 21394,  8465, 15562,\n",
      "        15064,  4778,    58,  3023,  2722, 23686,  2840,  3049, 27626, 18613,\n",
      "        29592, 15128, 30265, 19553,  4752,  4956,    85, 22227, 10538, 28423,\n",
      "        28473,  5568,  8878, 26711])\n",
      "tensor([ 2539,  1940, 11138,   241, 28679, 25861, 18294,  6500, 27358, 20758,\n",
      "        13106,  1957, 20997, 13109,  5295, 20746,  9855, 27539,   334, 21204,\n",
      "        16306,  9234, 26983,  1305, 22729, 27069, 21154, 17874,  3730, 10514,\n",
      "        17259, 28978, 13781, 29599, 26741, 12071, 15286, 27567,  4076, 28096,\n",
      "          952,  5571, 14795,   605,  6196,  5722,  5039, 23052, 22467, 15178,\n",
      "        17470,  7365,  6051, 10857,  1985,    33, 21107, 20275, 16031, 20148,\n",
      "        14874, 29555, 15343, 13532])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1874,   173,  6732,  1053,  6741, 28226, 27846,  8159, 12898,  7962,\n",
      "         9139, 19097,  8405, 16762,  7506, 24834, 16141,  8383,  1544,  7157,\n",
      "        21275,  7969,  7915, 11906, 28282,  9571, 24269,  7670, 24428, 23587,\n",
      "        15873, 13069, 11280,  7848, 24077,   638, 10622, 22571,  8475, 15992,\n",
      "        13310, 15728, 10811,  2860,  7186,  7285, 12691, 13197,  4282,  3374,\n",
      "        20173,  4154, 24449, 13458,  9980, 26025, 11110, 17841,  2222, 16954,\n",
      "         7086, 19600,  6963,  7251])\n",
      "tensor([22328,  4318, 13385, 13494, 24235, 29291,  6606, 27356, 18261, 14266,\n",
      "         1178,    80, 22531, 21440, 13850, 29045,  5079,  4856,   720,  1813,\n",
      "         3423,  4547,  7156,  2119, 22171,  3472, 24094,  5799, 24966, 10713,\n",
      "        14693,  1094, 23976, 23522, 27115, 17814, 27618, 14943,  8767, 11390,\n",
      "         6995, 12655, 12516, 12150, 21889, 15767,  3820,  6384,  9607, 12031,\n",
      "         3357, 14257, 11180, 24186, 19088, 27616, 27405,  6705,   180, 14952,\n",
      "        24580, 21986, 11819,   387])\n",
      "tensor([ 2066,  6515, 14392, 25945,  1348, 17845, 18991, 29454, 13430, 25358,\n",
      "        29311, 27450,  4834, 13936,  7367,  9690, 27370,  5387,  3395, 25702,\n",
      "        30269, 29566,  3436,  2233,  5909, 10080,  3105,  4389, 19355,  5342,\n",
      "        13519,  8339, 26205,  7224, 12350,  8619, 26405, 16936,  7188, 29384,\n",
      "        29337, 24389, 15896, 22425, 21308, 18295, 11976,  1436, 12552,  7057,\n",
      "         9712, 29174,   427, 13811, 20480, 24130,   270, 14792, 20329, 14851,\n",
      "         1801,  6796,  4523,  2098])\n",
      "tensor([ 4021, 25977,  5034,  7075, 24398, 26527,  1946, 15626, 29617,   164,\n",
      "        17751, 23752, 10327, 29871, 11365, 23106, 18377, 11159, 29612,  2802,\n",
      "        20152, 19544,  4018, 27635,  2675,  9090, 12940, 14043, 10786,    48,\n",
      "        22189, 18423,  9928, 19823,  9122,  8406, 21151, 12000, 12857, 15923,\n",
      "         6616,  4418,  2431,  4884,   757, 23936, 15029, 27294, 18053, 20278,\n",
      "         8073,  8128, 20068, 30307, 27775, 23763,  3438,  8952,  7036,  4099,\n",
      "         4263, 26164,   623, 20060])\n",
      "tensor([26760, 28172,  9793, 18460, 11216, 28861, 21137,   868,  2861, 13991,\n",
      "        23845,  3863, 28249, 14922, 12420,  5198, 15783, 19480, 29558, 11884,\n",
      "         7772,  9442, 14941, 27953, 16549,  5437, 22384, 28485, 30232, 29554,\n",
      "         7477,   624,  4455, 16957, 24500, 22919,  9799, 19586,  3753, 11522,\n",
      "        10396, 17211, 17614,  7958,  3890,  7959, 13219, 28056, 29818, 24635,\n",
      "          541,   534,  7411, 14924, 14425,  2461, 29753,  8227, 16815, 16415,\n",
      "         5296, 17104,  6548, 27572])\n",
      "tensor([25326,  9660, 24273, 10831, 21823, 11590,   244,  2959, 19501, 12259,\n",
      "        21710, 17038, 20642,  8748, 21162, 18973, 15375, 10414, 15327, 15239,\n",
      "        26593,  7599, 23879, 15030, 27175, 13817, 16255,  4770, 15784,   433,\n",
      "        25938,  1708, 12370,  8615,  6940,    73,  5070, 27619,  6785, 26876,\n",
      "        15688, 21490, 18687, 25261, 23266, 20911, 26873, 22433, 30350,  7311,\n",
      "        27480, 30123, 15560, 15410, 15830, 22941, 13899, 25714, 24944, 29759,\n",
      "         5207, 15460,  6569, 27829])\n",
      "tensor([  163, 23977, 13322,  7759, 21920,  1470,  8080,  4030, 21876,   464,\n",
      "         3411,  2856, 11831,  8547, 25795,  3668, 10184,  1358, 23594,  5216,\n",
      "        26582, 26454,  8915, 12680, 13592,   862, 18736, 14485, 21218,  6620,\n",
      "        13319,  9908,  3589, 15168,  5127, 12028, 26266,  8831, 17313, 29907,\n",
      "        18503,  3804,   286,  1811,  9268, 14798,  6699, 20988,  8852,  6904,\n",
      "         1820, 23741,  7035, 18998,  9237, 19374,  6861, 20171, 20791, 22113,\n",
      "        12748, 18500,  8501,  5476])\n",
      "tensor([24780, 25898, 21018,  8881, 25177,  5538, 11167, 26805,  2051, 15541,\n",
      "        16743, 24954,  9143, 21400, 10463,  6765,  8925, 26516, 23258, 19192,\n",
      "          502,   829,  9063, 15331,  1476, 22259, 14673,  8564, 24553,  1018,\n",
      "        19694, 10854, 25436,  2104, 12043, 30425, 18760, 26778, 14093, 23833,\n",
      "         6356, 23859, 24109,  2667, 14824, 20602, 14822, 15743,  1767, 17152,\n",
      "         1443,  1577, 18513, 16014,  9201, 26343, 30110, 20609, 22998, 30017,\n",
      "         8733, 24281, 27280, 17576])\n",
      "tensor([ 7113,  4067, 15837, 29099,  8980, 15406,  5389,   149, 15126, 27815,\n",
      "        22781, 14320, 25848, 20882,  6988,  3719, 17362, 26408, 13903,  6268,\n",
      "        17284,  4115, 11464, 19802,  8892, 30280, 10139,  3450,  9366, 12444,\n",
      "        29525,  6504,  5708, 21237,  5848, 20217, 30156,  8948,  3608, 29971,\n",
      "        20857, 26603, 10626, 14519, 23999, 16780, 14928, 21515,  9101, 14669,\n",
      "         4242,  7952, 17003, 17876, 19959, 12223, 13641, 20699, 25972,  7209,\n",
      "        14742, 14152, 13025,  5564])\n",
      "tensor([ 8812, 12143, 23837, 22422, 24171, 11476,   367, 14520,  1807, 12792,\n",
      "        20497, 21575, 18195,  9083,  5940,  9751, 18533, 27991, 23452, 23557,\n",
      "         6385,  8661, 24505, 25137,  8148,  4159, 24114,  4390, 17505, 18412,\n",
      "        15863, 17518, 14764, 25815, 18628, 13021, 30478, 17643, 12681, 24968,\n",
      "         9892, 12502,  3231, 21979, 30331, 12920, 14847, 27515, 14990,  1675,\n",
      "        24244, 18879, 22209,  7716,  9634, 18508,  8353,  2086, 20025, 14353,\n",
      "        10909,  8425, 28368, 12044])\n",
      "tensor([ 9944,  2307,  6246,  3130, 15678, 24558, 25005, 27102, 16426, 20321,\n",
      "         1883, 14699, 11896, 14842, 25934, 29530, 30202, 27592, 23251,   613,\n",
      "        15275,  4741,  3294,  6766,  3874,  3135, 23649, 28770, 13478, 29701,\n",
      "        28595, 26437,  6298, 23247,  2857, 19162,  4987, 23895, 29080, 12429,\n",
      "        24410, 18891, 11478, 19747,  2792, 14689, 18002, 17994, 13828, 28655,\n",
      "        29128, 11404, 27103,  7174,  2665, 26274, 26018, 26702, 17459, 14438,\n",
      "        13443, 22569,    28, 13015])\n",
      "tensor([ 7258, 22478, 28586,  2821, 27011, 26194, 20854, 10794, 20224, 18858,\n",
      "        23333, 16574,  2416, 20633, 17534,  8068, 13845,  1502, 20301, 10151,\n",
      "        28039, 26240,  6735, 13282, 29591, 28393,  2414, 24511, 12478,  1949,\n",
      "        26755, 13842, 20312,  5269, 27425,  4643,   876,  8490, 10863, 12629,\n",
      "         5142,  2674, 27462, 15310,  5144, 21498, 19954, 22521, 21899, 17458,\n",
      "        19265,  3184, 29686, 28729,   299, 24000, 12619, 14103, 10531, 20949,\n",
      "        19187, 21769, 19754,  7350])\n",
      "tensor([21290, 17446,  4548, 28784,  5963, 11351, 25219, 25254, 12533, 16774,\n",
      "        18234, 29391, 29368, 19460, 13039, 28309, 17728,  7510, 21837, 17392,\n",
      "         4395,  9462, 19452, 21601, 29390, 22787, 16153, 15415, 30353,  3509,\n",
      "        24150, 18370,  1729, 17267, 15405,  8982,  7912, 29619, 27052, 26329,\n",
      "        26080,  4640,  3973,  9867, 15738,  3401,  6337, 14961, 16139, 21245,\n",
      "        17898,  2473,   689,  2091, 21519, 19561, 24619, 16953, 16975, 15614,\n",
      "         7817,  5215,  1527,  9875])\n",
      "tensor([25831, 19256, 15587, 17433, 23021, 21006,  5719, 14247, 28225, 24879,\n",
      "        28289,  4054, 24372, 25891, 19550,  7038, 20970, 22671, 24097, 27748,\n",
      "        13838, 24243, 26874, 27152, 27517,  8836,  1819,  7933,  1249,  3022,\n",
      "         9233,  7392, 27882,  2718,  4731, 14434, 17702,  6636, 26631, 12807,\n",
      "        12447, 17741,  3218, 29408, 17520, 28776,  1024, 15843,  8079, 16618,\n",
      "        21175, 28206,  1220,  3939, 29001,  5122, 15119,  8979, 29946, 14668,\n",
      "         8076, 11551,  3937, 24581])\n",
      "tensor([ 5585, 20468,  3344, 12346,  5087, 23135,  5231,  8483, 24444, 22273,\n",
      "        12715, 26524, 24266,   298, 28146, 10427,   443, 24871, 15281,  6351,\n",
      "        28683, 25484, 13257,  4996,  5410, 30120, 26040, 25359, 12821,  4479,\n",
      "        24138, 19882, 29770, 29916,  7741,  2552, 14129, 11915, 18299,  1746,\n",
      "         8974, 22166, 20964, 24804,  6566, 12371, 19133, 18757, 18719, 16066,\n",
      "         9467, 21730,  6415,  2963,  6634,  9665,  7702,  2641, 20298,   330,\n",
      "        16796, 17600, 14314, 24197])\n",
      "tensor([ 2223,  6365, 12887, 20424,  3646, 21836, 28043,  6630,  3899, 10670,\n",
      "         8694,  3027,  6710,  6894, 11792,  5412,  6691, 16387,  6290,  7610,\n",
      "         8376,   455,  3042,  4739, 23162, 27481,  5065, 22664, 15723, 12452,\n",
      "        16455, 28392, 24694,  3446, 13331, 13102,  7120, 26808, 20035,  2580,\n",
      "         8741, 28542,   399,  6816, 20731, 26956,  1288, 13417,  7092, 27186,\n",
      "         6753, 24002, 17782, 27367, 23084, 15812,  6624, 30308,  4101, 13445,\n",
      "        26182, 24662,  5738, 24644])\n",
      "tensor([ 1329, 28642,  9859, 14617, 20925, 11737,  6429, 28092, 18039,  1088,\n",
      "        10766,  5702, 14981, 15323, 22774,  5265, 16265, 26140, 27177, 19443,\n",
      "         7451,  5049, 23204, 22816, 22385,  5247,  8359, 16200,  3507,  1228,\n",
      "        23588, 13000, 23861, 23860, 21043, 14656,    51, 21550,  7230, 18400,\n",
      "        10115, 24571, 29560,  9911, 23602, 22910, 15811, 30054, 22567, 21529,\n",
      "         9509,  1755,  6510, 25340,  5717, 25990, 13875,  5073, 19099,  5551,\n",
      "        11757, 11471,  7233, 21938])\n",
      "tensor([  885,  6764,   347, 17204, 14137, 15470,  3189, 29914, 19655,  3813,\n",
      "         3681, 20348,  8704,  4383,  9562, 23886,  1835,  5460,  2609, 20261,\n",
      "        19609, 30396,  4214, 26542, 16124,  5418, 29243,   842, 27692,  2823,\n",
      "         7420, 29285,  7065, 30432, 11333, 27166, 18151, 13821, 28179,  7104,\n",
      "         1848, 26606, 27207,  3972, 16275, 18238, 20012,  1615, 20999, 28652,\n",
      "        14779,  8541,  6563, 14337, 11268, 16537,  6942, 19193, 19918, 17697,\n",
      "         7801, 13196, 21960, 25968])\n",
      "tensor([30085,  7839, 24432, 25725,  7938,  3112,  9208,  6779, 27696, 22706,\n",
      "        26401, 14773, 28833, 12239, 26228, 22463, 19588, 13892, 10688, 27754,\n",
      "         9147,  5880, 21969,  7468, 24901, 12376, 29824, 22364, 18904, 14387,\n",
      "        27703,  8065, 27214, 16770,   336,  1700, 23080, 14593, 17158, 20778,\n",
      "        17909, 10515, 27955, 16367, 15792,   380, 27894, 17264,  8794, 19594,\n",
      "         1255, 12766, 11023, 20331, 23583,  6945, 19989, 18515, 20488,  6734,\n",
      "        27648,  7815, 21473, 23248])\n",
      "tensor([24743, 18392,  1017,  6820, 28597, 20425,  1206,  2618,  5409, 24748,\n",
      "         2778, 11768, 24062, 26048, 27887,  9913, 28019, 15445,  7669,  3969,\n",
      "        14556,  1299,  2341, 16070, 17051,  1950, 26270, 28809, 29217, 21265,\n",
      "         5179, 27924, 15564,   360, 19554, 20337,  1925,  5459, 19037,  3131,\n",
      "        23726, 21517, 22519, 25357, 27921, 20015, 25787, 24375,  5367,  1754,\n",
      "        25020,  8647,  3909, 25931, 16111,   551, 26727,    18, 24313, 28139,\n",
      "        29763,  4998, 17836,  9672])\n",
      "tensor([ 9862,   460, 17447, 17250, 17169, 20863, 29166,  4472,  8936, 24592,\n",
      "        22874, 23524, 14513, 19774, 24020, 16237, 22844, 17625, 15450, 23167,\n",
      "        15813,  9747, 27079, 20160, 13840, 14469, 11377,  4150,  8402,  1661,\n",
      "        17542, 11026, 12122,  3352, 30209, 22129,  7502, 21446,  5156,  7990,\n",
      "        20096,  5375,  6362,  7511, 19732, 13721,  3361, 30468, 10400, 15993,\n",
      "          493, 25510,  9577, 22753,  4710, 19175,  2669, 28725, 13117, 23345,\n",
      "        12049, 30282, 28964, 22897])\n",
      "tensor([ 2962, 28843, 28332, 16176, 12500,  3066,  5629, 17513,    30, 15421,\n",
      "          430, 11536, 22595,  2973,  1841, 18631,  9210,  9176, 18926,  5770,\n",
      "         9181, 13802, 21989,  4589,   844,  9360, 27857, 23736, 14927,  3323,\n",
      "         2742, 12225,  8207,  6278,  4394, 20638, 18228, 10332, 14858,  4020,\n",
      "        24916, 22410, 13702, 10663, 12222,  6869,  8823, 20447, 14801, 21416,\n",
      "         3672, 24673, 17865, 21411, 15579, 23042, 14346, 29187, 11804, 23175,\n",
      "        14774, 14985, 22026, 21598])\n",
      "tensor([19285, 22647,   474, 21447, 21225, 29223, 16175, 29970,  2533, 13381,\n",
      "        29783,  1415, 11245, 24567,  9696, 17558,  8163,  6219,  9416,  5618,\n",
      "        21147, 20420, 26227, 13286, 28434, 27777, 23858,  8125, 25395,  3527,\n",
      "        29906, 14027, 16955,  2951, 25038,  2194, 12930,  6188, 16077,  1113,\n",
      "        24977, 19009,  6739, 27699, 25024, 14598, 13420, 25006, 21595, 21339,\n",
      "        26384,  4830, 14879,   678, 21640,  4783, 28401, 29436, 20448, 12702,\n",
      "         4727, 25818,   569, 23945])\n",
      "tensor([ 5653, 22511, 10828, 16171, 28759,  2320,   645, 21085,  7665,  3916,\n",
      "        18160,  4517,  4756, 25521, 18558,  1068,  7973, 28108,  1832,  8779,\n",
      "        10586, 25817, 28097, 27514, 19863,  2741,  7682,     3,  6864, 22849,\n",
      "        10577, 17791, 16504, 25479, 19060, 15686, 24228, 22846, 11562, 29455,\n",
      "        30103, 11578,  9922,  5865, 29943,  4613, 10434,   726,  1481,  4063,\n",
      "        18786,  3014, 17922, 22481, 17480,  6387, 21732,  2536, 11775, 21192,\n",
      "          669,  8825, 26630, 12634])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([23818,  9835, 17255,  4624, 27242, 25366,  9443, 29009, 30007, 28470,\n",
      "        16104, 19610, 27642, 18798, 11813,  5947,  1842,  4328,  5875, 25997,\n",
      "         3729, 28521, 26180, 14227, 11050,  5508, 12598, 28178,  5948, 22872,\n",
      "        17567, 25010,  2515, 15787, 29101, 14856, 28480, 29940, 11147, 29618,\n",
      "         5895, 17517, 27366,  9127,  5894,  1694, 28764, 18703, 16281,  7768,\n",
      "        18177,  3149, 15719, 16103, 25726, 15235,  1616, 29446, 10570, 29123,\n",
      "        29066,  7862, 19440,  1770])\n",
      "tensor([14100, 15117, 29681, 21340,  8680, 21034, 23397,  1320,  5986, 27332,\n",
      "         9235, 13915, 21615, 13305, 14826,  9062, 16766, 25278,  1077,  5362,\n",
      "         7062, 14882,  2770, 18004,  8612, 28432, 18915, 15080, 29354, 13690,\n",
      "        14171,  1580, 21540, 29142, 24623,  2603,  4767, 14888,  7172, 22857,\n",
      "        18818, 21333, 15671, 21089, 29140, 27419,  6572,  7757, 17545, 23306,\n",
      "        19812,  2563,  8896, 28992,  9784, 22011, 29074, 29380, 21250, 22301,\n",
      "        19949, 23201, 13680, 21180])\n",
      "tensor([28257,  6978, 29225,   642, 15057, 26398, 18247, 18061, 23472, 25100,\n",
      "        28074, 28700, 11134,  9613,  2558,  7587, 19271, 26178, 18374,  7348,\n",
      "        19651, 21999, 13473,  5991, 18308, 27270,  7123,  9091, 23203, 16206,\n",
      "         7306,  7447,  1750,  6970,  6587,  4531, 25114, 25086, 17597, 17551,\n",
      "          405,  9873,  1021, 23307, 12272, 24232, 25398, 29348, 28569, 15832,\n",
      "        19313, 18806, 10494,  2281, 21829, 18560,  5929, 18183, 25771, 26066,\n",
      "        16342, 17258, 18458, 17794])\n",
      "tensor([ 2150,   111,  3787,  6265, 28176, 13099,  9218, 18290, 13710, 21912,\n",
      "        25606,  3229, 10689, 14769, 15103, 11438, 28395,  4620,  5497, 29275,\n",
      "        29644,  1300,  4294, 23607,  4513,  3274, 17621, 29042,  5015, 14323,\n",
      "         8520,    41, 19139, 28352,  4322,  9887, 20828,  2896, 13988, 30005,\n",
      "        20666, 26918,  3862, 28906, 15251, 28051, 18514,  3028,  6046, 25220,\n",
      "        23309,  2172, 28460, 29700, 26855,  8284, 20918, 19753, 24940, 28643,\n",
      "        19942,  3839, 10867,  4823])\n",
      "tensor([ 4883,  1357, 29682,   850, 30364,  4936,  2342, 13746,  7807,  4096,\n",
      "         2832,  9209,  6436,  8188, 14159,  2158, 17454, 12770,  4602, 23188,\n",
      "        27197, 15312, 23579, 16203, 18328,  4176, 16347, 28120,   287, 19814,\n",
      "         5307,   578, 15435, 16847, 20455, 28261,  5883, 30108, 28247,  1762,\n",
      "        29392, 27348,  6807, 12914, 19884,  6072, 18276,  8009, 14282, 25560,\n",
      "        16854, 20678,   661,  8758, 26122,  6784,  7053, 22952, 17524,  7143,\n",
      "         2054, 12885,  6117, 22100])\n",
      "tensor([ 3741, 11724,   640, 28046, 24769, 20896,   871,   783,  9390, 22821,\n",
      "        21407,  3019, 26817,  4093,  2772, 21179,   540, 19438,   770, 26222,\n",
      "        10530,  8618, 14240, 24909, 30070, 22369, 10572, 14898, 13609, 25291,\n",
      "        18828, 10903, 12591, 27018,  6091, 27587,  1771, 26259, 14807, 28693,\n",
      "         2187, 22343,   545, 28823, 22351, 25923, 13968, 23953, 29336, 11778,\n",
      "         4412, 29233, 12383, 17926, 13003, 28966,  9343,   321, 26732, 17369,\n",
      "        26142,  4028,  2301,  1861])\n",
      "tensor([21261,  3297,  5333, 26083, 18117, 19650,  6070, 24438, 22117,  3977,\n",
      "        25365, 23480, 24906,  1379, 29788, 13521, 20810,   310, 23273,  5464,\n",
      "        22868,   416, 10773, 26139,  6037, 23538, 25789, 19131,  6089, 18077,\n",
      "        19330, 26120, 18259,  9049, 18766,  1919, 15710, 17670, 27230, 27014,\n",
      "         3377,  6336,  1263,  9579,  6150, 19016, 10136, 16020, 29683, 19488,\n",
      "        25690, 24480,   651, 29260, 18933, 30456, 25159, 28286, 25031,  2290,\n",
      "         8572, 14615, 28426, 23835])\n",
      "tensor([28511,  2280, 14508, 18028, 28419,  2475,  7245,  8600, 13265, 22069,\n",
      "        24605, 26166,   830,  9942, 23778, 14750, 23156, 29620,  7154,  2866,\n",
      "        21381, 17188,  2578, 29536,  9121, 19165,  5365, 15976, 19338, 19277,\n",
      "        25154,   975, 15208, 27403, 12904,  3506, 24617, 20111,  3992, 21579,\n",
      "         7643, 25875, 10695, 11817, 14319, 29603, 13262, 21506, 18691, 25180,\n",
      "        17060,  9963,  5436,   913, 16194,  1753,  6411, 25993,  8681, 22388,\n",
      "        10716, 18974,  1279, 26129])\n",
      "tensor([29676,  1776, 28984, 10173, 24278, 20444, 23044, 28821,   179,  2144,\n",
      "         4595, 19095, 26604, 25376,  8977, 19105, 21081,  6519, 21510, 28446,\n",
      "        12698, 11786,  6153, 20961, 14119, 13772,  5910, 14875, 23867, 13157,\n",
      "        21939,  6557, 25171, 27654,  6953, 22429, 11518,  7789, 19054, 10004,\n",
      "        22586, 12725, 24111,  5204, 24572, 17388, 21512, 17357,  4782,  2034,\n",
      "        26100, 11693,  7536, 22819, 25992, 21283, 27537, 11179, 23493,  1210,\n",
      "        23267, 29193, 14121,  5888])\n",
      "tensor([27034, 20442, 16363, 23119,  2036,  5500, 15041,  8965,  3205,  5623,\n",
      "        12810, 18979, 25133, 17002, 13270,   907, 19447,  2080, 17645, 23027,\n",
      "         2097,  7681, 20041,  9363,  2413,  7207, 24596, 19273, 22912, 21345,\n",
      "        24628,  4915,  5651, 20082,  5354, 25401, 28456, 19171, 15791, 14249,\n",
      "        22311, 22673, 10877, 25315,  1111, 29108, 10359, 21666, 18841,  7600,\n",
      "        16434,  3129,  1417, 18043, 14635,  7354, 10985, 29519, 27393,  4847,\n",
      "        30459, 10627, 20691, 26596])\n",
      "tensor([ 1907,  6439, 14727, 10420, 11706, 23595, 16742, 24312, 22237, 27728,\n",
      "        20893, 17900,  4908,  1142, 24661, 21795, 19317, 22848, 12009,  4391,\n",
      "         2235, 16495, 22222, 23090,     6, 19378, 20811,  3725, 26414, 16962,\n",
      "        13247,  9311, 12759, 22535,  8183, 19322, 22367, 18621, 16752,  5114,\n",
      "        10812,  1052, 11818, 16577,  2744, 11326, 21046, 23061,  9221,  1587,\n",
      "        16112, 12127, 13471,  5090, 12474, 24210,  3406,  1674, 21427, 20273,\n",
      "        24681, 12551,  5546, 18929])\n",
      "tensor([ 1983, 26042, 29689, 23475, 23762, 22598, 18597, 21643, 20146,   629,\n",
      "        26807, 20870, 24208, 23404,  7443,   972, 19494,  2257, 15369, 14041,\n",
      "         7204,  9563, 14011,  5424,  2550, 17126, 23604, 21566, 30376, 19408,\n",
      "         8519, 11407, 11434, 10012, 10768, 25509, 22151,  6934, 14031, 27845,\n",
      "        16308,  8395, 22843,  6141, 27423, 14217, 19149,  3983, 13510,  7892,\n",
      "         5343, 27593,  3163, 13540,  4456, 16552, 11358, 29787,  4247,  6364,\n",
      "         7955,  7763, 25917, 15469])\n",
      "tensor([ 6618, 20311, 24678, 27860, 10616,  1945,   512, 30003, 12522,   716,\n",
      "        10284, 15776,  1687,  8014, 12001, 22655, 12057, 15566,  5593, 14166,\n",
      "         2497, 21860, 22908,  7690, 16074, 16299,  9290, 23110, 27996, 22964,\n",
      "          204, 22999, 27087, 26969, 24477, 12963, 25661, 27795, 21623, 23197,\n",
      "         5627, 24401,  4870, 17712,  3935, 23114, 24420,  2392, 10206, 15888,\n",
      "        24584, 19679, 29488, 28970, 15154, 10175, 24390,   579, 13837, 20675,\n",
      "         9349, 27108, 13468, 10244])\n",
      "tensor([29163, 20299, 17296, 10441, 22312,  3868,  4435,  6653,  2401, 13823,\n",
      "         7652,  3553,  1202,  8827, 16476, 21433,  3348,  9632, 15052, 12758,\n",
      "        26137, 26633, 15449, 21844,   672,   436, 10099, 22961, 11483,  6216,\n",
      "        24274, 17418,  6437, 19391, 21522, 16351, 30055, 11488,  3852, 14198,\n",
      "        11082, 21214,  7548, 19441,  7940, 12299,  1666,  2586,  7724, 20366,\n",
      "        12270, 14090, 14161, 29983, 12578, 20614, 16619, 30088,  1914, 23164,\n",
      "        23988,  5692, 27139,   229])\n",
      "tensor([ 6952, 25629,  4091, 13580, 16710, 16693, 14737,  3194, 25458,  5776,\n",
      "        12871, 23082,  8133, 22713,  3397,  9308,  2737, 17527,  6538,  8586,\n",
      "         6590,  6588, 20946, 12178, 29954,  7934, 28537, 19967, 13743,  3300,\n",
      "        29639, 15097, 12563, 17796, 20871, 11548,   169, 19813,  4992, 10254,\n",
      "        16777,  3924,  4110, 21020, 28412, 25916,   307,  5104,  2532, 21908,\n",
      "         3558, 29707,  8632, 16209, 14478, 28285,  9646,  1566, 14907, 28560,\n",
      "         1205, 23753,  6886, 11846])\n",
      "tensor([13165, 27772, 15417,  7524, 21576, 15244, 13699,   363, 23064, 28376,\n",
      "        13657, 27375,  9145, 16511,  4536,   300,  2191, 23433, 12006, 15214,\n",
      "        14272,  1243, 19426, 28598, 26491, 21633,  4302,  1641,  6709,  1472,\n",
      "         8322, 20598,  1742,  1981, 11616,  8470, 20690, 20707,  3713,  8815,\n",
      "        22786, 20814, 29180,  7323, 27733, 11378, 14154, 25271, 12313,   943,\n",
      "         4329, 15373, 13073, 28207, 10592,  1987, 13912, 25301, 17710, 19324,\n",
      "        29269, 13628, 22690,  6521])\n",
      "tensor([  198, 28867, 22238, 27634, 14614, 14176, 29277, 10737,   561,  7024,\n",
      "         3481, 26671, 26280, 28017,  6635, 16095, 26657, 21552,  3500, 16025,\n",
      "         8416,  1079, 25470,  1592, 17663,  9569, 13341, 25314, 10360,  1155,\n",
      "         3437, 12382, 12416, 27048, 27886,  3771, 20136,  7335, 21131, 29522,\n",
      "        24315, 10673, 13546, 16694, 24870,  7900, 18848,  6499, 26212,   744,\n",
      "          390,  2787, 27299, 20250, 16423, 17771,  4682, 29545,  3001, 14034,\n",
      "        20088, 14362, 29798, 12648])\n",
      "tensor([22785, 10521,  1048, 20460,  5529,  4107, 17873, 22697,  4545, 14236,\n",
      "        18186,   776, 14167,  4678, 13143, 12023, 26738,  4587, 28275, 14828,\n",
      "        27990, 15011, 11687,  1798, 25037, 19053, 28622, 24602,   993,  2178,\n",
      "         6079, 10468, 23690,  3831, 12392,  7099,   525, 20969, 19289, 27389,\n",
      "         1418,  9878, 18168, 29423, 29151, 12212, 28869, 20759, 29862, 25432,\n",
      "         4623,   933, 11411, 20588, 26699, 25312, 18159,   828,  3737,  4957,\n",
      "        10273, 14805, 18330, 12575])\n",
      "tensor([20729, 19778, 18895,  5952,  6599, 10052, 22674, 12883,  2476, 21026,\n",
      "        17294,  8457,  9813, 24493,  9073, 21826,  2537, 15048, 17353, 23912,\n",
      "         4182,  8288, 19697, 16612, 10506, 21409, 10462, 13302, 21260, 10756,\n",
      "        16941,  4267,  7281, 19212, 20114, 16731, 20208, 29889,  3915,  9071,\n",
      "         5069, 17299,  5552, 29281, 26197, 20248, 24809, 17434, 24876,  5788,\n",
      "        10676, 29326,  6514, 15885,   931, 11953, 30040, 21319,   129,  2797,\n",
      "        28365, 15816,  6292, 24451])\n",
      "tensor([17693, 26793, 22681,  1591, 18910,   194, 24723,  1825, 16090,  7527,\n",
      "        16995, 20890,  3887, 24413, 14254, 19868, 12206,  8590, 17688, 28658,\n",
      "        23928, 23661, 16115,  9567, 20665, 27121, 19972,  2844,  8336,   382,\n",
      "        11958,  7644, 16818, 27557,  1738,  7800, 11886,  8096, 12175,   423,\n",
      "         8005, 10333,  2079, 30189,  6559, 15495, 19469,  7863, 12549, 23795,\n",
      "         4516, 14555,  3784, 26267,  9985, 15409, 12534, 23605,  2081, 11122,\n",
      "        14658, 24167, 27781, 29843])\n",
      "tensor([13383, 14559, 11214,  7197, 22788, 22563, 21384,  2815,  4401, 28481,\n",
      "        20846, 21583, 30231, 29727,  1752,  2221,  1624, 10908,  1540,  7158,\n",
      "         1364, 14457, 29933, 19155, 24209,  1368, 22944, 24551, 15653, 28638,\n",
      "        16325, 25903,  6737, 14588,  5550, 24010, 28311, 27623, 29055, 20951,\n",
      "        10300,  7210,  5107, 16972,  3232, 19106, 28552, 10267, 21310,   604,\n",
      "         2334, 19653,  1392, 26883, 27876,  4805, 10945, 21104, 18125, 10025,\n",
      "        14914, 11091, 13236, 21921])\n",
      "tensor([ 8337,  9475, 18911, 15663, 19205, 20388, 11379, 30413, 12663,  5218,\n",
      "        14412, 22184,  3442, 19305, 21279, 14115,  6370, 10323, 10835, 19593,\n",
      "         9536,  4116, 12331, 28520, 27327, 16898, 18796,  2309, 20619, 29371,\n",
      "        25678,  2508, 19831,  4781, 23698,  8613,  5206, 13740, 24039, 20754,\n",
      "         9314, 10322,  3679,  8630,  4410, 10446, 11312, 30159, 11909,  9929,\n",
      "        27711,   458, 17123,  9456, 15273, 17084, 13542, 25166,  6453,  3213,\n",
      "        16987, 14483, 10815,  1894])\n",
      "tensor([23737, 11789, 26199, 19136, 14613, 21879, 23880, 27027, 20668, 20794,\n",
      "        21254,  5241,   342, 23046, 12282,  1169,  2776, 16392, 24828, 29307,\n",
      "        10994, 26642, 11604, 23672, 17155, 28786,  6082, 12524, 10219, 23881,\n",
      "        21022, 13728, 15224, 16396,  6648,  6103, 27260, 22987, 18405, 19755,\n",
      "        21454, 25631, 27512, 21244, 23222,  7409, 29321,  8331, 19448, 16340,\n",
      "         7495, 26967,  4470, 15690, 23411, 27636, 30394, 17907, 12131, 23603,\n",
      "        29308, 12828, 27570,  8484])\n",
      "tensor([16645, 18350,  7438, 21694,  4015, 18749,  8398,  9764, 13427, 20402,\n",
      "        12499, 20045, 27353,  9540, 10502, 12929, 30163, 10635, 25270,  6276,\n",
      "         2910, 24165, 14419, 20984, 18421, 17058,  1784, 20105,  4277,   773,\n",
      "        27344,  5014,  7129, 21602, 11106, 14303, 27454,  1242, 26427, 16707,\n",
      "        17919, 25520, 11728, 16263, 28202, 27129, 28849, 24538,  9587,  6148,\n",
      "         8150,  1707, 29434,  4984,  7300,   266, 27912, 23194, 21675, 11588,\n",
      "        22871,  6319,  2450, 25083])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20942, 21669, 19465, 15287, 18799, 24268, 20266,  2934, 19620, 29338,\n",
      "         6907,  3439, 16373, 10814, 28440,   273,  3490,  9129, 17082, 19807,\n",
      "        16584, 21887,  4179, 22147, 12240, 19995, 27387,  6169,  8526, 22403,\n",
      "        18685, 20830, 24630, 11414, 13133, 17657,  7943, 24005, 30440, 27452,\n",
      "         8309, 18512, 13738,  4466, 17613, 26885, 18697, 11144, 21370, 13160,\n",
      "        29684,  7526,  6987, 23221,  1576, 20855, 16328, 17044, 14681, 17717,\n",
      "        24383, 14234,  3309, 16810])\n",
      "tensor([ 4442, 13566,  2493, 14037,  7557,  8462, 27137, 22199, 12264, 15072,\n",
      "         2422, 17961, 18155, 19428, 26111, 26269,  3859, 10844,  5522, 24665,\n",
      "        16805, 22593, 26472, 21305, 22115, 21078,  4468,  1664,  3477, 25305,\n",
      "        16213, 12068, 23190,  5727, 17336, 26835, 18239,  9905, 28822,  3670,\n",
      "         5289,  4368,  8567, 23217,  2384, 25279, 19147, 25924, 26856, 11234,\n",
      "         1780,  6073,  5036,  9853, 19969, 14969, 15360, 21086,  6293, 25526,\n",
      "        22981, 26252, 20157, 14222])\n",
      "tensor([15508, 10940,  5873, 30128, 25959,  8153, 21309, 10508,  9081, 29298,\n",
      "        13089, 12981,  8352,  4265, 22144, 19621, 19682,  7685, 11279, 19014,\n",
      "        15703, 21019, 11586,   248, 17273, 30031, 24120, 26106,  6558,  5989,\n",
      "         2808, 22512,  3817,  4143,  2063, 23547,  6297, 13674,  4973, 19856,\n",
      "        16063, 27615, 25161, 23476,  3556,  6725, 28329,  8200, 10802, 22712,\n",
      "         2367, 22885, 28674, 15858, 20755,  7503, 18031, 20552, 27071, 23058,\n",
      "        15380, 13831, 27688, 20006])\n",
      "tensor([28667, 17077,  7906,  3559, 29201, 27972, 13717,  3628,  3259, 27317,\n",
      "         5705,  8110, 10146, 20452, 11412, 12283,  2500, 11983,  2841,  9608,\n",
      "         3860, 19245, 14565,  7385, 23740, 10511, 25282, 29145, 23883, 16043,\n",
      "        24354,  5118, 29831, 15909, 12982,  3572,  6780,  2452,  3379, 17658,\n",
      "        11356,  3420, 11035,  7377,  8387,  9307,  7290,  1323, 28749, 16917,\n",
      "        18244,  9937, 10710, 19945, 21090, 22034, 29704, 21320, 29379, 25856,\n",
      "        29263,  1560, 17366, 22762])\n",
      "tensor([26748, 16395,  1208, 17904,  5134,   630, 19681,  7237, 23616, 21961,\n",
      "        17356, 21330, 10096,  9941, 29553, 24938, 17297, 25321, 11556, 28967,\n",
      "         4439, 28518,  1073, 19546, 28744, 12926, 27471,  4136,  1359,  5902,\n",
      "        10125,  9836, 18319,   564, 29576, 15070, 29294, 13843,  4952, 24218,\n",
      "        17179,  8614,  3704,  6155,  1873, 12328, 25487, 28503,  3268, 11746,\n",
      "        28850, 24947, 10630,  7715, 16897,  5031, 19783,  1161,  4058, 19124,\n",
      "         9291, 21715,   798, 22448])\n",
      "tensor([ 5815,  2732, 30238,  2426, 29516, 13645,  9219,  8366, 10188, 13866,\n",
      "         6614, 13136, 14070,   160, 21442,  5359, 23438,  1184, 15385,  7161,\n",
      "        13410,  6579, 19510, 29334, 10102, 19042, 26390,   467,  6334, 11899,\n",
      "        14563, 17495, 15570, 14030, 13115,  9252, 16778,  2427, 22617,  6409,\n",
      "         3040, 26412, 28845, 11640,  1963,  9711, 12785,  2575, 11860, 12330,\n",
      "         8145, 17680,  9735, 25453, 15751, 30438, 28721, 15077, 12445, 16407,\n",
      "        26165, 17004,  4316, 17315])\n",
      "tensor([22366, 10916, 18469,  3468, 12761, 21367, 17959, 30395, 26975, 17125,\n",
      "        21450, 22314, 14857, 10516,  1449,  9378,  7778,  4961, 21774, 23515,\n",
      "        19194, 27194,  2684, 17396, 27461, 17543,  1726, 14206, 10917, 20785,\n",
      "        21639, 23678, 18840,  7597, 19799, 25728, 13872, 12380, 15644, 15075,\n",
      "        23502, 10104, 24202,  3848, 20335, 26074, 22979,  8093, 21644, 26821,\n",
      "        15496, 19179,  7865, 27245,  7638, 18562, 27864,  1177,  2173, 27469,\n",
      "        19696, 22313, 29557,  9719])\n",
      "tensor([26953, 10912,  9769, 25698,  7628, 10547,  3115,  7677, 11084, 26174,\n",
      "        23747, 20474,  1558, 14671, 18759, 18118, 10982, 15969, 21804,  3724,\n",
      "        18409, 18219,  7200, 22610, 28262, 15161,  2620,  3943, 26500,  5781,\n",
      "        15319, 27092, 30068, 16283, 19917, 18544,  4022, 15899,  2258, 21917,\n",
      "        22295, 22468, 25540, 28269,  4922, 13960, 23073,  3276, 28326,  3563,\n",
      "        19142,  8560, 16337, 13835, 26452,  8311, 18809, 17287,  3586, 14624,\n",
      "        20198,  4588, 14218, 26713])\n",
      "tensor([  858,  9027,   101, 13535,  7995, 11554,  4001, 21383, 14431, 13408,\n",
      "        30180, 24729, 16550,  1921, 23836, 12202,  2459, 16271, 29630, 26273,\n",
      "          522,  1362,  9555, 18808, 15348, 20487, 20071, 15432, 14074, 25637,\n",
      "        24330,  7127, 23683, 18839,  6996, 28527, 15898, 19475,  9724,  7870,\n",
      "        11075,  6919, 14528, 12805,  4549, 13654, 11617,  1423,  4161,  2252,\n",
      "        23009, 12995, 28617, 26893, 27521, 27532, 24853,  6505, 22143, 26151,\n",
      "        26378,  7978, 20084, 25476])\n",
      "tensor([10959, 22156,  3778, 26758,  1411, 13981, 18059,  5214,  8498, 10062,\n",
      "        26208, 30347, 16590, 12035, 25538, 17026,  9987,  2606, 10424, 23537,\n",
      "         8656, 26992,  2847,  9172, 20492, 15397, 17217,  2974,  1579, 29478,\n",
      "         8168, 11417, 16525, 24684, 11890, 24526, 28153,  4800, 25909, 30255,\n",
      "        24169,  8930, 21548, 20714,  6170,  6921, 23218,  4916,  4426, 14989,\n",
      "        18194, 14992, 24481, 26939, 19962,  2879, 30067, 21098, 17064, 26997,\n",
      "         7219, 11683, 20405, 19672])\n",
      "tensor([ 6876, 25273, 25651,  5718, 16326, 25012, 30024, 25866,  9918,  3347,\n",
      "          257,  8393, 24393, 12769,   746, 28032, 12274,  4313,  7362,  1698,\n",
      "        20109, 17491,   857, 29116, 21631, 25199, 11177, 15223, 18924,  1336,\n",
      "         1538,  1187, 21762, 25506, 25208, 29007, 10658,  8449, 17120,  2241,\n",
      "        15876,  3338, 13765, 22262,  9051, 18753, 16654,  9653,  3750, 24229,\n",
      "        26959, 11627, 28612,  1393, 15276, 27220, 30408, 11698, 19138,  3827,\n",
      "         1915, 23377,   182,  8914])\n",
      "tensor([15802, 15649,  2556,  7626, 26608, 16700,  7244, 16280, 30392,  2482,\n",
      "         7901,  8937, 28611, 27918, 25307,  7304, 16114, 20950, 17601, 25800,\n",
      "         5128, 26950,  7481, 30140, 10674,  9872, 11000, 30290, 13457, 16307,\n",
      "        21692, 19522, 24641, 11209, 11681, 11861,  8891, 19794, 23966,  6890,\n",
      "          465, 17097, 18263, 25456, 15295,   594, 17857, 25471, 24328, 16453,\n",
      "        26586, 22604,  7675,   234,  2498, 26467, 29316,  4357, 12641, 25406,\n",
      "        24964, 23241, 23427, 18153])\n",
      "tensor([19907, 23978,  8910, 10445, 25483, 23151, 29677,  6412, 28692,  2582,\n",
      "         2858, 23432, 29098, 16121, 14710, 17289,  3167, 17716,  8588, 25630,\n",
      "         8249,  9005,  2790, 16162, 28982, 17824,  3530,  2716,  9703, 25710,\n",
      "        24868, 28712, 20629, 24534,  8094,  5754, 19464, 19686, 12506,  1809,\n",
      "         4931, 11070,  2297, 22775,  9413, 27106, 25901,  4480,  5706, 25384,\n",
      "         1943, 14064, 22236, 16845,  5874, 24215, 29952,  5212, 18950, 14595,\n",
      "         4424,  4607, 24450,    90])\n",
      "tensor([11995, 15341, 13942, 12870, 22306,  9934,  7947,   653, 13926, 10944,\n",
      "        29580, 22526,  7325,  2143, 15772,  4177, 24996,  9492, 12869, 14591,\n",
      "        14310, 25129,  3251,  3818, 11859, 28856, 17937,  2919, 12845, 10656,\n",
      "        15749, 14904, 27773,  2997, 12743, 11346, 24727, 17916, 30433, 26318,\n",
      "        23280, 12867, 24904, 11025,  2244, 24683,   548, 17894,  9120,  1096,\n",
      "        22286,  2249, 11999, 12803, 11663, 11929,  7834,  7887, 20611,  2013,\n",
      "        30344,  1116, 25765, 16152])\n",
      "tensor([ 7469, 17186, 14024, 29329, 24247,  5187,  7167,  1394,  4670,  2576,\n",
      "         8403, 13656,  4308, 14098, 15616, 22725, 18013, 22945, 19477,   293,\n",
      "        18868,    84, 21119, 24397, 28737,  2123, 27170,  1360,  4728, 23300,\n",
      "         3026,  9622, 14585, 11874, 22772,   456,  8701, 25203,  8839, 28995,\n",
      "         7098,  2052, 28356, 19715,  2572, 14715, 26183, 24101, 30421, 17021,\n",
      "         4276, 23311,  9255, 14466, 15563, 24792, 10270, 12147,  1772, 10390,\n",
      "        25843, 13278,  3921, 13832])\n",
      "tensor([ 9280, 30369,  2391, 23949, 24019, 28828,  1926, 27013, 28629,  4493,\n",
      "        29964, 18024, 25201,   445, 18052, 15818, 23651,  7570, 23711,  3485,\n",
      "         3685, 10066, 24971, 17990, 15446,    75, 14783,  5202, 18034,  7027,\n",
      "        13594,  7222, 29740, 24043,  1550,  2232, 21017, 23254,  1974, 26352,\n",
      "         5621, 25626,  2323, 28354, 19101, 16196,  2302, 12241, 22269, 24839,\n",
      "        13359, 11869, 16763, 17610, 14113,  2424,  9459,  6775, 19019,  4810,\n",
      "         2827,  3068,  6585, 22414])\n",
      "tensor([ 7692,  7343, 21726,  1571, 17790, 12166,  9275, 16933, 11982,  7549,\n",
      "         6918, 24448, 30409, 19083, 26942, 10800, 29153,  7535,  3421,  2814,\n",
      "        12254, 22107,  9231, 26150,  8629, 19534, 17076,   499,  9940,  6329,\n",
      "         3378, 19944,  4645, 26890,  3835,  2065, 21628, 17108, 20912,  7991,\n",
      "        26027,  1794,  6880, 10778, 10827, 28211,  1290,  2356, 30311,  4846,\n",
      "        13788, 27398, 21414, 20165, 17731, 16851, 19935, 17386, 14602,  4089,\n",
      "        22580, 13492, 11980, 26768])\n",
      "tensor([15231, 11577, 17457,  6224, 20995, 25609,   820, 20805, 23775, 21122,\n",
      "         6802, 25590, 16706,  1663, 25258,  2677,  8456, 29438, 20399, 16135,\n",
      "         2017,   351, 25212, 23478,  5709, 12719, 30215,  8696, 21893, 14535,\n",
      "          259, 12367, 22537,  3491, 28037,  9052, 17595,  9224,  2774,  1744,\n",
      "        27684, 15708, 26623,  1294, 21468, 15490, 15308,  9400, 26130, 28034,\n",
      "        20523, 15788,  4377,  5637, 12814,  6380,  6717,  5567, 26857, 25187,\n",
      "        24015, 26380,  4172, 30361])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7d37c5e66f2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a seq2seq model\n",
    "\n",
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_sizes, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(classes, hidden_size) \n",
    "                                         for classes, hidden_size in embedding_sizes])\n",
    "        self.rnn = nn.LSTM(self.input_size, config.rnn_num_hidden, \n",
    "                           config.rnn_num_layers, dropout=config.enc_rnn_dropout, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, x_emb):\n",
    "        x, x_emb = x.permute(1,0,2), x_emb.permute(1,0,2) # make time-major\n",
    "        output_emb = [emb(x_emb[:, :, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        output_emb = torch.cat(output_emb, 2)\n",
    "        \n",
    "        x_rnn = torch.cat([x, output_emb], 2)\n",
    "        \n",
    "        output, hidden = self.rnn(x_rnn)\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "# Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_sizes, output_size, config):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(classes, hidden_size) \n",
    "                                         for classes, hidden_size in embedding_sizes])\n",
    "        self.rnn = nn.LSTM(self.input_size, config.rnn_num_hidden, \n",
    "                           config.rnn_num_layers, dropout=config.dec_rnn_dropout, bidirectional=True)\n",
    "        self.pred = nn.Linear(config.rnn_num_hidden*2, output_size)\n",
    "\n",
    "    def forward(self, x, x_emb, hidden):\n",
    "        x, x_emb = x.permute(1,0,2), x_emb.permute(1,0,2) # make time-major\n",
    "        output_emb = [emb(x_emb[:, :, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        output_emb = torch.cat(output_emb, 2)\n",
    "        x_rnn = torch.cat([x, output_emb], 2)\n",
    "        \n",
    "        output, hidden = self.rnn(x_rnn, hidden)\n",
    "#         shape = output.size()\n",
    "#         output = self.pred(output.view(-1, output.size(2)))\n",
    "#         output = output.view(shape[0], shape[1]).permute(1, 0)\n",
    "        output = self.pred(output[0])\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales):\n",
    "        batch_size, pred_len = x_dec.shape[0:2]\n",
    "        \n",
    "        # create a tensor to store the outputs\n",
    "        predictions = torch.zeros(batch_size, pred_len).to(config.device)\n",
    "        \n",
    "        encoder_output, hidden = self.encoder(x_enc, x_enc_emb)\n",
    "        \n",
    "        # for each prediction timestep, use the output of the previous step, \n",
    "        # concatenated with other features as the input\n",
    "                \n",
    "        for timestep in range(0, pred_len):\n",
    "            \n",
    "            if timestep == 0:\n",
    "                # for the first timestep of decoder, use previous steps' sales\n",
    "                dec_input = torch.cat([x_dec[:, 0, :], x_last_day_sales], dim=1).unsqueeze(1)\n",
    "            else:\n",
    "                # for next timestep, current timestep's output will serve as the input along with other features\n",
    "                dec_input = torch.cat([x_dec[:, timestep, :], decoder_output], dim=1).unsqueeze(1)\n",
    "            \n",
    "            # the hidden state of the encoder will be the initialize the decoder's hidden state\n",
    "            decoder_output, hidden = self.decoder(dec_input, x_dec_emb[:, timestep, :].unsqueeze(1), hidden)\n",
    "            \n",
    "            # add predictions to predictions tensor\n",
    "            predictions[:, timestep] = decoder_output.view(-1)\n",
    "            \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    \n",
    "    # hidden dimension and no. of layers will be the same for both encoder and decoder\n",
    "    rnn_num_hidden = 256\n",
    "    rnn_num_layers = 2\n",
    "    enc_rnn_dropout = 0.0\n",
    "    dec_rnn_dropout = 0.0\n",
    "    \n",
    "    num_epochs = 10\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "config = Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embeddings): ModuleList(\n",
       "      (0): Embedding(3049, 50)\n",
       "      (1): Embedding(7, 4)\n",
       "      (2): Embedding(10, 5)\n",
       "    )\n",
       "    (rnn): LSTM(105, 256, num_layers=2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embeddings): ModuleList(\n",
       "      (0): Embedding(3049, 50)\n",
       "      (1): Embedding(7, 4)\n",
       "      (2): Embedding(10, 5)\n",
       "    )\n",
       "    (rnn): LSTM(105, 256, num_layers=2, bidirectional=True)\n",
       "    (pred): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sizes = [(3049, 50), (7, 4), (10, 5)] # for item_id, dept_id, store_id respectively\n",
    "num_features_enc = 46 + sum([j for i, j in embedding_sizes])\n",
    "num_features_dec = 46 + sum([j for i, j in embedding_sizes])\n",
    "enc = Encoder(num_features_enc, embedding_sizes, config)\n",
    "dec = Decoder(num_features_dec, embedding_sizes, 1, config)\n",
    "model = Seq2Seq(enc, dec)\n",
    "model.to(config.device)\n",
    "# writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-040dc5d0890b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loss and Optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_loss():\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for i, (x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales, y) in enumerate(notebook.tqdm(val_loader)):\n",
    "        x_enc, x_dec = Variable(x_enc).to(config.device), Variable(x_dec).to(config.device)\n",
    "        x_enc_emb, x_dec_emb = Variable(x_enc_emb).to(config.device), Variable(x_dec_emb).to(config.device)\n",
    "        x_last_day_sales = Variable(x_last_day_sales).to(config.device)\n",
    "        y = Variable(y).to(config.device)\n",
    "\n",
    "        preds = model(x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales)\n",
    "        loss = criterion(preds, y)\n",
    "        loss_iter = loss.data.cpu().numpy()\n",
    "        losses.append(loss_iter)\n",
    "\n",
    "    print('Validation Loss: %.4f' % np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8640486de104f49ab7198a17dd1af8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10], Iter [477/476] Loss: 2.3053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10457302fc68470a865b44fbca050251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.3677\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31ebd1160b04fbfa4401fb22b89d9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/10], Iter [477/476] Loss: 2.2163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e938a63e3aa4a2cb0a4252d90db336b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.2312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c216a15af34020ae3af097ce623ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/10], Iter [477/476] Loss: 2.1666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9b6395579b40c18765d57596904be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.2313\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af341d4cfb5411f881dd48c934f3f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/10], Iter [477/476] Loss: 2.1116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0723704d5c2b4cc896d65f702711cd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.1783\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0a9c6cc5be4842bdae0f5fba7eb78a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/10], Iter [477/476] Loss: 2.0902\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567ade19bd794df79d4d04066264ffdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.2125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3047de1da1444a9adbe215a8cab3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/10], Iter [477/476] Loss: 2.0432\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cee968efffc4964830e1639fc82415d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.2756\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d42651c81a43ea97befb1c84f88c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7/10], Iter [477/476] Loss: 2.0266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b07ef8a39c45e680fe6127c8d97b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.1981\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c90a465542348fb8feefbe7e5186d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8/10], Iter [477/476] Loss: 1.9879\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef8bfc50db04ce2b9afbf9770dce300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.2167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123d477ece024223ba683b54da3114e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9/10], Iter [477/476] Loss: 1.9722\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e4c29ff7f04e47b5d31528928f5222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.2564\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6377bc9a594449d8ef0c5d8dc65d24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [10/10], Iter [477/476] Loss: 1.9353\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355549ca8f5c468d8882a8d3320d33e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.2858\n"
     ]
    }
   ],
   "source": [
    "# Progress bar\n",
    "for epoch in range(config.num_epochs):\n",
    "    progbar = notebook.tqdm(train_loader)\n",
    "    losses = []\n",
    "    for i, (x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales, y) in enumerate(progbar):\n",
    "        model.train()\n",
    "        x_enc, x_dec = Variable(x_enc).to(config.device), Variable(x_dec).to(config.device)\n",
    "        x_enc_emb, x_dec_emb = Variable(x_enc_emb).to(config.device), Variable(x_dec_emb).to(config.device)\n",
    "        x_last_day_sales = Variable(x_last_day_sales).to(config.device)\n",
    "        y = Variable(y).to(config.device)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales)\n",
    "#         writer.add_graph(model, [x_enc, x_dec, x_last_day_sales])\n",
    "        loss = criterion(preds, y)\n",
    "        loss_iter = loss.data.cpu().numpy()\n",
    "        progbar.set_description(\"loss = %0.3f \" % np.round(loss_iter, 3))\n",
    "        losses.append(loss_iter)\n",
    "        \n",
    "        loss = torch.mean(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n",
    "           %(epoch+1, config.num_epochs, i+1, len(train_dataset)//config.batch_size, \n",
    "             np.mean(losses)))\n",
    "    get_val_loss()\n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../submissions/sub1/model.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embeddings): ModuleList(\n",
       "      (0): Embedding(3049, 50)\n",
       "      (1): Embedding(7, 4)\n",
       "      (2): Embedding(10, 5)\n",
       "    )\n",
       "    (rnn): LSTM(105, 256, num_layers=2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embeddings): ModuleList(\n",
       "      (0): Embedding(3049, 50)\n",
       "      (1): Embedding(7, 4)\n",
       "      (2): Embedding(10, 5)\n",
       "    )\n",
       "    (rnn): LSTM(105, 256, num_layers=2, bidirectional=True)\n",
       "    (pred): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../submissions/sub1/model.pth.tar'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a39362ec6f84c13abba6e4ce8114269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-1ab7ac025eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_enc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dec_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_last_day_sales\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mx_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mx_enc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dec_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_enc_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dec_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mx_last_day_sales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_last_day_sales\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for i, (x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales) in enumerate(notebook.tqdm(test_loader)):\n",
    "        x_enc, x_dec = Variable(x_enc).to(config.device), Variable(x_dec).to(config.device)\n",
    "        x_enc_emb, x_dec_emb = Variable(x_enc_emb).to(config.device), Variable(x_dec_emb).to(config.device)\n",
    "        x_last_day_sales = Variable(x_last_day_sales).to(config.device)\n",
    "\n",
    "        preds.append(model(x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales).data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.concatenate(preds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.iloc[:predictions.shape[0], 1:] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('../submissions/sub1/submission.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bb3c2cdf9b44c695f8b6d6fabed11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 1.9693\n"
     ]
    }
   ],
   "source": [
    "get_val_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>FOODS_3_823</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>FOODS_3_824</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows × 1919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id        item_id    dept_id   cat_id  \\\n",
       "0      HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "1      HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
       "2      HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
       "3      HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
       "4      HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
       "...                              ...            ...        ...      ...   \n",
       "30485    FOODS_3_823_WI_3_validation    FOODS_3_823    FOODS_3    FOODS   \n",
       "30486    FOODS_3_824_WI_3_validation    FOODS_3_824    FOODS_3    FOODS   \n",
       "30487    FOODS_3_825_WI_3_validation    FOODS_3_825    FOODS_3    FOODS   \n",
       "30488    FOODS_3_826_WI_3_validation    FOODS_3_826    FOODS_3    FOODS   \n",
       "30489    FOODS_3_827_WI_3_validation    FOODS_3_827    FOODS_3    FOODS   \n",
       "\n",
       "      store_id state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  \\\n",
       "0         CA_1       CA    0    0    0    0  ...       1       3       0   \n",
       "1         CA_1       CA    0    0    0    0  ...       0       0       0   \n",
       "2         CA_1       CA    0    0    0    0  ...       2       1       2   \n",
       "3         CA_1       CA    0    0    0    0  ...       1       0       5   \n",
       "4         CA_1       CA    0    0    0    0  ...       2       1       1   \n",
       "...        ...      ...  ...  ...  ...  ...  ...     ...     ...     ...   \n",
       "30485     WI_3       WI    0    0    2    2  ...       2       0       0   \n",
       "30486     WI_3       WI    0    0    0    0  ...       0       0       0   \n",
       "30487     WI_3       WI    0    6    0    2  ...       2       1       0   \n",
       "30488     WI_3       WI    0    0    0    0  ...       0       0       1   \n",
       "30489     WI_3       WI    0    0    0    0  ...       0       0       0   \n",
       "\n",
       "       d_1907  d_1908  d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0           1       1       1       3       0       1       1  \n",
       "1           0       0       1       0       0       0       0  \n",
       "2           1       1       1       0       1       1       1  \n",
       "3           4       1       0       1       3       7       2  \n",
       "4           0       1       1       2       2       2       4  \n",
       "...       ...     ...     ...     ...     ...     ...     ...  \n",
       "30485       0       0       0       1       0       0       1  \n",
       "30486       0       0       0       0       0       1       0  \n",
       "30487       2       0       1       0       0       1       0  \n",
       "30488       0       0       1       0       3       1       3  \n",
       "30489       0       0       0       0       0       0       0  \n",
       "\n",
       "[30490 rows x 1919 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1912, 1940)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_t_b, test_t_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1941-1914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.948881</td>\n",
       "      <td>0.818636</td>\n",
       "      <td>0.834599</td>\n",
       "      <td>0.884738</td>\n",
       "      <td>0.988404</td>\n",
       "      <td>1.120274</td>\n",
       "      <td>1.269215</td>\n",
       "      <td>1.171244</td>\n",
       "      <td>1.076180</td>\n",
       "      <td>...</td>\n",
       "      <td>1.075340</td>\n",
       "      <td>1.220519</td>\n",
       "      <td>1.376329</td>\n",
       "      <td>1.103644</td>\n",
       "      <td>0.979420</td>\n",
       "      <td>0.934300</td>\n",
       "      <td>0.943113</td>\n",
       "      <td>1.029701</td>\n",
       "      <td>1.175751</td>\n",
       "      <td>1.238253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0.667062</td>\n",
       "      <td>0.418846</td>\n",
       "      <td>0.454884</td>\n",
       "      <td>0.442493</td>\n",
       "      <td>0.471557</td>\n",
       "      <td>0.527329</td>\n",
       "      <td>0.580185</td>\n",
       "      <td>0.485661</td>\n",
       "      <td>0.440305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463578</td>\n",
       "      <td>0.565727</td>\n",
       "      <td>0.692143</td>\n",
       "      <td>0.484468</td>\n",
       "      <td>0.435793</td>\n",
       "      <td>0.441920</td>\n",
       "      <td>0.459359</td>\n",
       "      <td>0.497804</td>\n",
       "      <td>0.574895</td>\n",
       "      <td>0.581653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0.980776</td>\n",
       "      <td>0.854881</td>\n",
       "      <td>0.910752</td>\n",
       "      <td>0.979821</td>\n",
       "      <td>1.090250</td>\n",
       "      <td>1.198755</td>\n",
       "      <td>1.203921</td>\n",
       "      <td>1.045154</td>\n",
       "      <td>1.003860</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082921</td>\n",
       "      <td>1.206002</td>\n",
       "      <td>1.246968</td>\n",
       "      <td>0.972033</td>\n",
       "      <td>0.934462</td>\n",
       "      <td>0.958826</td>\n",
       "      <td>1.016848</td>\n",
       "      <td>1.128089</td>\n",
       "      <td>1.271931</td>\n",
       "      <td>1.235085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>2.781727</td>\n",
       "      <td>2.314433</td>\n",
       "      <td>2.333030</td>\n",
       "      <td>2.248819</td>\n",
       "      <td>2.350440</td>\n",
       "      <td>2.592122</td>\n",
       "      <td>2.818342</td>\n",
       "      <td>2.500714</td>\n",
       "      <td>2.382025</td>\n",
       "      <td>...</td>\n",
       "      <td>2.314852</td>\n",
       "      <td>2.642580</td>\n",
       "      <td>2.921061</td>\n",
       "      <td>2.104538</td>\n",
       "      <td>1.960665</td>\n",
       "      <td>1.912035</td>\n",
       "      <td>1.912758</td>\n",
       "      <td>2.017019</td>\n",
       "      <td>2.209183</td>\n",
       "      <td>2.143029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1.882275</td>\n",
       "      <td>1.600861</td>\n",
       "      <td>1.684266</td>\n",
       "      <td>1.818450</td>\n",
       "      <td>2.112558</td>\n",
       "      <td>2.437965</td>\n",
       "      <td>2.440682</td>\n",
       "      <td>1.948949</td>\n",
       "      <td>1.707919</td>\n",
       "      <td>...</td>\n",
       "      <td>1.813270</td>\n",
       "      <td>2.178214</td>\n",
       "      <td>2.371747</td>\n",
       "      <td>1.740101</td>\n",
       "      <td>1.583631</td>\n",
       "      <td>1.612978</td>\n",
       "      <td>1.788136</td>\n",
       "      <td>2.171239</td>\n",
       "      <td>2.618240</td>\n",
       "      <td>2.512470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60975</th>\n",
       "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60976</th>\n",
       "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60977</th>\n",
       "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60978</th>\n",
       "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60979</th>\n",
       "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60980 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id        F1        F2        F3        F4  \\\n",
       "0      HOBBIES_1_001_CA_1_validation  0.948881  0.818636  0.834599  0.884738   \n",
       "1      HOBBIES_1_002_CA_1_validation  0.667062  0.418846  0.454884  0.442493   \n",
       "2      HOBBIES_1_003_CA_1_validation  0.980776  0.854881  0.910752  0.979821   \n",
       "3      HOBBIES_1_004_CA_1_validation  2.781727  2.314433  2.333030  2.248819   \n",
       "4      HOBBIES_1_005_CA_1_validation  1.882275  1.600861  1.684266  1.818450   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "60975    FOODS_3_823_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "60976    FOODS_3_824_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "60977    FOODS_3_825_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "60978    FOODS_3_826_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "60979    FOODS_3_827_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "             F5        F6        F7        F8        F9  ...       F19  \\\n",
       "0      0.988404  1.120274  1.269215  1.171244  1.076180  ...  1.075340   \n",
       "1      0.471557  0.527329  0.580185  0.485661  0.440305  ...  0.463578   \n",
       "2      1.090250  1.198755  1.203921  1.045154  1.003860  ...  1.082921   \n",
       "3      2.350440  2.592122  2.818342  2.500714  2.382025  ...  2.314852   \n",
       "4      2.112558  2.437965  2.440682  1.948949  1.707919  ...  1.813270   \n",
       "...         ...       ...       ...       ...       ...  ...       ...   \n",
       "60975  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "60976  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "60977  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "60978  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "60979  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "\n",
       "            F20       F21       F22       F23       F24       F25       F26  \\\n",
       "0      1.220519  1.376329  1.103644  0.979420  0.934300  0.943113  1.029701   \n",
       "1      0.565727  0.692143  0.484468  0.435793  0.441920  0.459359  0.497804   \n",
       "2      1.206002  1.246968  0.972033  0.934462  0.958826  1.016848  1.128089   \n",
       "3      2.642580  2.921061  2.104538  1.960665  1.912035  1.912758  2.017019   \n",
       "4      2.178214  2.371747  1.740101  1.583631  1.612978  1.788136  2.171239   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "60975  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "60976  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "60977  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "60978  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "60979  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            F27       F28  \n",
       "0      1.175751  1.238253  \n",
       "1      0.574895  0.581653  \n",
       "2      1.271931  1.235085  \n",
       "3      2.209183  2.143029  \n",
       "4      2.618240  2.512470  \n",
       "...         ...       ...  \n",
       "60975  0.000000  0.000000  \n",
       "60976  0.000000  0.000000  \n",
       "60977  0.000000  0.000000  \n",
       "60978  0.000000  0.000000  \n",
       "60979  0.000000  0.000000  \n",
       "\n",
       "[60980 rows x 29 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff108800e97481f8204c992bdc31018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = [], []\n",
    "for i, (x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales, y) in enumerate(notebook.tqdm(val_loader)):\n",
    "        x_enc, x_dec = Variable(x_enc).to(config.device), Variable(x_dec).to(config.device)\n",
    "        x_enc_emb, x_dec_emb = Variable(x_enc_emb).to(config.device), Variable(x_dec_emb).to(config.device)\n",
    "        x_last_day_sales = Variable(x_last_day_sales).to(config.device)\n",
    "        y_true.append(y)\n",
    "\n",
    "        y_pred.append(model(x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales).data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.cat(y_true, 0).data.cpu().numpy()\n",
    "y_pred = np.concatenate(y_pred, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2369509"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_true, y_pred, squared=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
