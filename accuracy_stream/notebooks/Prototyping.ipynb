{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from tqdm import notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pickle as pkl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../../data/sales_train_validation.csv')\n",
    "sell_prices = pd.read_csv('../../data/sell_prices.csv')\n",
    "calendar = pd.read_csv('../../data/calendar.csv')\n",
    "sample_submission = pd.read_csv('../../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.date =  pd.to_datetime(calendar.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar['relative_year'] = 2016 - calendar.year\n",
    "\n",
    "# convert month, day and weekday to cyclic encodings\n",
    "calendar['month_sin'] = np.sin(2 * np.pi * calendar.month/12.0)\n",
    "calendar['month_cos'] = np.cos(2 * np.pi * calendar.month/12.0)\n",
    "calendar['day_sin'] = np.sin(2 * np.pi * calendar.date.dt.day/calendar.date.dt.days_in_month)\n",
    "calendar['day_cos'] = np.cos(2 * np.pi * calendar.date.dt.day/calendar.date.dt.days_in_month)\n",
    "calendar['weekday_sin'] = np.sin(2 * np.pi * calendar.wday/7.0)\n",
    "calendar['weekday_cos'] = np.cos(2 * np.pi * calendar.wday/7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_events = ['SuperBowl', 'ValentinesDay', 'PresidentsDay', 'StPatricksDay',\n",
    "                  'OrthodoxEaster', 'Cinco De Mayo', \"Mother's day\", 'MemorialDay',\n",
    "                  \"Father's day\", 'IndependenceDay', 'Eid al-Fitr', 'LaborDay',\n",
    "                  'ColumbusDay', 'Halloween', 'EidAlAdha', 'VeteransDay',\n",
    "                  'Thanksgiving', 'Christmas', 'NewYear', 'OrthodoxChristmas', \n",
    "                  'MartinLutherKingDay', 'Easter']\n",
    "multi_day_events = ['LentStart', 'LentWeek2', 'Purim End', 'Pesach End',\n",
    "                    'NBAFinalsStart', 'NBAFinalsEnd', 'Ramadan starts', 'Chanukah End']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate columns for each event\n",
    "for event in one_day_events:\n",
    "    calendar[event] = [1 if val == event else 0 for val in calendar.event_name_1]\n",
    "    calendar.loc[calendar.event_name_2 == event, event] = 1\n",
    "    \n",
    "calendar['Lent'] = [1 if val == 'LentStart' else 0 for val in calendar.event_name_1]\n",
    "calendar.loc[calendar.event_name_2 == 'LentStart', 'Lent'] = 1\n",
    "calendar['Purim'] = [1 if val == 'Purim End' else 0 for val in calendar.event_name_1]\n",
    "calendar.loc[calendar.event_name_2 == 'Purim End', 'Purim'] = 1\n",
    "calendar['Pesach'] = [1 if val == 'Pesach End' else 0 for val in calendar.event_name_1]\n",
    "calendar.loc[calendar.event_name_2 == 'Pesach End', 'Pesach'] = 1\n",
    "calendar['Ramadan'] = [1 if val == 'Ramadan starts' else 0 for val in calendar.event_name_1]\n",
    "calendar.loc[calendar.event_name_2 == 'Ramadan starts', 'Ramadan'] = 1\n",
    "calendar['Chanukah'] = [1 if val == 'Chanukah End' else 0 for val in calendar.event_name_1]\n",
    "calendar.loc[calendar.event_name_2 == 'Chanukah End', 'Chanukah'] = 1\n",
    "\n",
    "calendar['NBAFinals'] = [1 if (val == 'NBAFinalsStart') else None for val in calendar.event_name_1]\n",
    "calendar.loc[(calendar.event_name_2 == 'NBAFinalsStart'), 'NBAFinals'] = 1\n",
    "calendar.loc[\n",
    "    (calendar.event_name_1 == 'NBAFinalsEnd') | (calendar.event_name_2 == 'NBAFinalsEnd'), 'NBAFinals'] = 0\n",
    "\n",
    "\n",
    "## for multi-day events, fill value as 1 from start to end\n",
    "# Lent ends approx 6 weeks from the start\n",
    "calendar['Lent'] = calendar['Lent'].rolling(min_periods=1, window=7*6).sum()\n",
    "# Purim lasts just 2 days\n",
    "calendar['Purim'] = calendar['Purim'].shift(-1).rolling(min_periods=1, window=2).sum()\n",
    "# Purim usually lasts for 9 days\n",
    "calendar['Pesach'] = calendar['Pesach'].shift(-8).rolling(min_periods=1, window=9).sum()\n",
    "# both start and end dates for NBA Finals have been given\n",
    "calendar['NBAFinals'] = calendar['NBAFinals'].fillna(method='ffill').fillna(0)\n",
    "calendar.loc[\n",
    "    (calendar.event_name_1 == 'NBAFinalsEnd') | (calendar.event_name_2 == 'NBAFinalsEnd'), 'NBAFinals'] = 1\n",
    "# Ramadan ends approx 30 days from the start\n",
    "calendar['Ramadan'] = calendar['Ramadan'].rolling(min_periods=1, window=30).sum()\n",
    "# Chanukah lasts for 9 days\n",
    "calendar['Chanukah'] = calendar['Chanukah'].shift(-8).rolling(min_periods=1, window=9).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_df = calendar[['wm_yr_wk', 'd', 'snap_CA', 'snap_TX', 'snap_WI', 'relative_year',\n",
    "                        'month_sin', 'month_cos', 'day_sin', 'day_cos', 'weekday_sin', 'weekday_cos',\n",
    "                        'SuperBowl', 'ValentinesDay', 'PresidentsDay', 'StPatricksDay', 'OrthodoxEaster',\n",
    "                        'Cinco De Mayo', \"Mother's day\", 'MemorialDay', \"Father's day\", 'IndependenceDay',\n",
    "                        'Eid al-Fitr', 'LaborDay', 'ColumbusDay', 'Halloween', 'EidAlAdha', 'VeteransDay',\n",
    "                        'Thanksgiving', 'Christmas', 'NewYear', 'OrthodoxChristmas', 'MartinLutherKingDay',\n",
    "                        'Easter', 'Lent', 'Purim', 'Pesach', 'Ramadan', 'Chanukah', 'NBAFinals']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all dfs, keep calender_df features separate and just concat them for each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.id = train_data.id.str[:-11]\n",
    "sell_prices['id'] = sell_prices['item_id'] + '_' + sell_prices['store_id']\n",
    "\n",
    "# add empty columns for future data\n",
    "train_data = pd.concat([train_data, pd.DataFrame(columns=['d_'+str(i) for i in range(1914, 1970)])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode categorical features using either one-hot or label encoding (for embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = ['cat_id', 'state_id'] \n",
    "label = ['item_id', 'dept_id', 'store_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[[str(i)+'_enc' for i in one_hot]] = train_data[one_hot]\n",
    "one_hot_encoder = ce.OneHotEncoder(cols=[str(i)+'_enc' for i in one_hot], use_cat_names=True)\n",
    "one_hot_encoder.fit(train_data)\n",
    "train_data = one_hot_encoder.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[[str(i)+'_enc' for i in label]] = train_data[label]\n",
    "label_encoder = ce.OrdinalEncoder(cols=[str(i)+'_enc' for i in label])\n",
    "label_encoder.fit(train_data)\n",
    "train_data = label_encoder.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substract one from label encoded as pytorch uses 0-indexing\n",
    "for col in [str(i)+'_enc' for i in label]:\n",
    "    train_data[col] = train_data[col] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape, change dtypes and add previous day sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsh/venvs/torch/lib/python3.7/site-packages/pandas/core/frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.melt(train_data, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',\n",
    "                                      'cat_id_enc_HOBBIES', 'cat_id_enc_HOUSEHOLD', 'cat_id_enc_FOODS',\n",
    "                                       'state_id_enc_CA', 'state_id_enc_TX', 'state_id_enc_WI',\n",
    "                                      'item_id_enc', 'dept_id_enc', 'store_id_enc'],\n",
    "                  var_name='d', value_vars=['d_'+str(i) for i in range(1, 1970)], value_name='sales')\n",
    "\n",
    "# change dtypes to reduce memory usage\n",
    "data_df[['sales']] = data_df[['sales']].fillna(-1).astype(np.int16)  # fill future sales as -1\n",
    "calendar_df[one_day_events + ['Lent', 'Purim', 'Pesach', 'Ramadan', 'Chanukah', 'NBAFinals', \n",
    "                              'snap_CA', 'snap_TX', 'snap_WI', 'relative_year']] = calendar_df[\n",
    "    one_day_events + ['Lent', 'Purim', 'Pesach', 'Ramadan', 'Chanukah', 'NBAFinals',\n",
    "                     'snap_CA', 'snap_TX', 'snap_WI', 'relative_year']].astype(np.int8)\n",
    "data_df[['cat_id_enc_HOBBIES', 'cat_id_enc_HOUSEHOLD', 'cat_id_enc_FOODS',\n",
    "         'state_id_enc_CA', 'state_id_enc_TX', 'state_id_enc_WI']] = data_df[\n",
    "    ['cat_id_enc_HOBBIES', 'cat_id_enc_HOUSEHOLD', 'cat_id_enc_FOODS',\n",
    "     'state_id_enc_CA', 'state_id_enc_TX', 'state_id_enc_WI']].astype(np.int8)\n",
    "data_df[['item_id_enc', 'dept_id_enc', 'store_id_enc']] = data_df[\n",
    "    ['item_id_enc', 'dept_id_enc', 'store_id_enc']].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.merge(right=calendar_df[['d', 'wm_yr_wk']], on=['d'], how='left')\n",
    "data_df = data_df.merge(right=sell_prices[['id', 'wm_yr_wk', 'sell_price']], on=['id', 'wm_yr_wk'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.sell_price = data_df.sell_price.fillna(0.0)\n",
    "data_df['prev_day_sales'] = data_df.groupby(['id'])['sales'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove data for d_1\n",
    "data_df = data_df.dropna()\n",
    "calendar_df = calendar_df[calendar_df.d != 'd_1']\n",
    "\n",
    "# change dtypes\n",
    "data_df[['prev_day_sales']] = data_df[['prev_day_sales']].astype(np.int16)\n",
    "data_df[['sell_price']] = data_df[['sell_price']].astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add previous day totals of aggregated series as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total\n",
    "data_df = data_df.merge(right=\n",
    "                        data_df.groupby(['d'])[['prev_day_sales']].sum().astype(\n",
    "                            np.int32).add_suffix('_all').reset_index(),\n",
    "                        on=['d'], how='left')\n",
    "# category level\n",
    "data_df = data_df.merge(right=\n",
    "                        data_df.groupby(['d', 'cat_id'])[['prev_day_sales']].sum().astype(\n",
    "                            np.int32).reset_index().pivot(\n",
    "                            index='d', columns='cat_id', values='prev_day_sales').add_prefix('prev_d_cat_'),\n",
    "                        on=['d'], how='left')\n",
    "# state level\n",
    "data_df = data_df.merge(right=\n",
    "                        data_df.groupby(['d', 'state_id'])[['prev_day_sales']].sum().astype(\n",
    "                            np.int32).reset_index().pivot(\n",
    "                            index='d', columns='state_id', values='prev_day_sales').add_prefix('prev_d_state_'),\n",
    "                        on=['d'], how='left')\n",
    "# store level\n",
    "data_df = data_df.merge(right=\n",
    "                        data_df.groupby(['d', 'store_id'])[['prev_day_sales']].sum().astype(\n",
    "                            np.int32).reset_index().pivot(\n",
    "                            index='d', columns='store_id', values='prev_day_sales').add_prefix('prev_d_store_'),\n",
    "                        on=['d'], how='left')\n",
    "# department level\n",
    "data_df = data_df.merge(right=\n",
    "                        data_df.groupby(['d', 'dept_id'])[['prev_day_sales']].sum().astype(\n",
    "                            np.int32).reset_index().pivot(\n",
    "                            index='d', columns='dept_id', values='prev_day_sales').add_prefix('prev_d_dept_'),\n",
    "                        on=['d'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3a972267a3b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# remove category columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wm_yr_wk'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dept_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_df' is not defined"
     ]
    }
   ],
   "source": [
    "# remove category columns\n",
    "del data_df['wm_yr_wk']\n",
    "del data_df['item_id']\n",
    "del data_df['dept_id']\n",
    "del data_df['cat_id']\n",
    "del data_df['store_id']\n",
    "del data_df['state_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = data_df.id.nunique()\n",
    "num_timesteps = data_df.d.nunique()\n",
    "data_df = data_df.set_index(['id', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_feats = ['sell_price', 'cat_id_enc_HOBBIES', 'cat_id_enc_HOUSEHOLD', 'cat_id_enc_FOODS', 'state_id_enc_CA',\n",
    "                 'state_id_enc_TX', 'state_id_enc_WI', 'item_id_enc', 'dept_id_enc', 'store_id_enc']\n",
    "enc_only_feats = data_df.columns.difference(['sales', 'sell_price', 'prev_day_sales'] + enc_dec_feats)\n",
    "\n",
    "sales_data_index = data_df.index\n",
    "Y = data_df.sales.values.reshape(num_timesteps, num_samples).T\n",
    "\n",
    "X_enc_only_feats = np.array(data_df[enc_only_feats]).reshape(num_timesteps, num_samples, -1)\n",
    "gc.collect()\n",
    "\n",
    "X_enc_dec_feats = np.array(data_df[enc_dec_feats]).reshape(num_timesteps, num_samples, -1)\n",
    "\n",
    "X_prev_day_sales = data_df.prev_day_sales.values.reshape(num_timesteps, num_samples)\n",
    "\n",
    "calendar_index = calendar_df.d\n",
    "X_calendar = np.array(calendar_df.iloc[:, 2:])\n",
    "X_calendar_cols = list(calendar_df.columns[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dict = {'sales_data_index' : sales_data_index, 'calendar_index' : calendar_index, \n",
    "#              'X_prev_day_sales' : X_prev_day_sales, \n",
    "#              'X_enc_only_feats': X_enc_only_feats, 'X_enc_dec_feats' : X_enc_dec_feats,\n",
    "#              'enc_dec_feat_names': enc_dec_feats, 'enc_only_feat_names': enc_only_feats,\n",
    "#              'X_calendar' : X_calendar, 'X_calendar_cols' : X_calendar_cols, \n",
    "#              'Y' : Y,\n",
    "#             'one_hot_encoder': one_hot_encoder, 'label_encoder': label_encoder}\n",
    "\n",
    "# # pickle data\n",
    "# with open('../data/data.pickle', 'wb') as f:\n",
    "#     pkl.dump(data_dict, f, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data.pickle', 'rb') as f:\n",
    "    data_dict = pkl.load(f)\n",
    "    \n",
    "sales_data_index = data_dict['sales_data_index']\n",
    "calendar_index = data_dict['calendar_index']\n",
    "X_prev_day_sales = data_dict['X_prev_day_sales']\n",
    "X_enc_only_feats = data_dict['X_enc_only_feats']\n",
    "X_enc_dec_feats = data_dict['X_enc_dec_feats']\n",
    "X_calendar = data_dict['X_calendar']\n",
    "X_calendar_cols = data_dict['X_calendar_cols']\n",
    "Y = data_dict['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.utils.data\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset (Input Pipeline)\n",
    "class CustomDataset(data_utils.Dataset):\n",
    "    '''\n",
    "    Custom dataset\n",
    "    \n",
    "    Let:\n",
    "    training period timesteps = [0, N]\n",
    "    prediction period timesteps = [N+1, N+P]\n",
    "    \n",
    "    Arguments:\n",
    "    X_prev_day_sales : previous day sales for training period ([0, N])\n",
    "    X_enc_only_feats : aggregated series' previous day sales for training period ([0, N])\n",
    "    X_enc_dec_feats : sell price and categorical features for training and prediction period ([0, N+P])\n",
    "    X_calendar : calendar features for training and prediction period ([0, N+P])\n",
    "    X_last_day_sales : the actual sales for the day before the start of the prediction period (for timestep N)\n",
    "                       (this will serve as the first timestep's input for the decoder)\n",
    "    Y : actual sales, denoting targets for prediction period ([N+1, N+P])\n",
    "    \n",
    "    Returns:\n",
    "    List of torch arrays:\n",
    "    x_enc: concatenated encoder features (except embedding)\n",
    "    x_enc_emb: concatenated encoder embedding features\n",
    "    x_dec: concatenated decoder features (except embedding)\n",
    "    x_dec_emb: concatenated decoder embedding features\n",
    "    x_last_day_sales: the actual sales for the day before the start of the prediction period\n",
    "    y: targets (only in training phase)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, X_prev_day_sales, X_enc_only_feats,\n",
    "                 X_enc_dec_feats, X_calendar, X_last_day_sales, \n",
    "                 Y=None, transform=None):\n",
    "        self.X_prev_day_sales = X_prev_day_sales\n",
    "        self.X_enc_only_feats = X_enc_only_feats\n",
    "        self.X_enc_dec_feats = X_enc_dec_feats\n",
    "        self.X_calendar = X_calendar\n",
    "        self.X_last_day_sales = X_last_day_sales\n",
    "        \n",
    "        if Y is not None:\n",
    "            self.Y = torch.from_numpy(Y).float()\n",
    "        else:\n",
    "            self.Y = None\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X_prev_day_sales.shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc_timesteps = self.X_prev_day_sales.shape[0]\n",
    "        dec_timesteps = self.X_enc_dec_feats.shape[0] - enc_timesteps\n",
    "        num_embedding = 3\n",
    "        \n",
    "        # input data for encoder\n",
    "        x_enc_dec_feats_enc = self.X_enc_dec_feats[:enc_timesteps, idx, :-num_embedding]\n",
    "#         x_enc_only_feats = self.X_enc_only_feats[:, idx, :].reshape(enc_timesteps, -1)\n",
    "        x_prev_day_sales_enc = self.X_prev_day_sales[:, idx].reshape(-1, 1)\n",
    "        x_calendar_enc = self.X_calendar[:enc_timesteps, :]\n",
    "#         x_enc = np.concatenate([x_enc_dec_feats_enc, x_calendar_enc, \n",
    "#                                 x_prev_day_sales_enc, x_enc_only_feats], axis=1)\n",
    "        x_enc = np.concatenate([x_enc_dec_feats_enc, x_calendar_enc, \n",
    "                                x_prev_day_sales_enc], axis=1)\n",
    "        x_enc_emb = self.X_enc_dec_feats[:enc_timesteps, idx, -num_embedding:].reshape(enc_timesteps, -1)\n",
    "        \n",
    "        # input data for decoder\n",
    "        x_enc_dec_feats_dec = self.X_enc_dec_feats[enc_timesteps:, idx, :-num_embedding].reshape(dec_timesteps, -1)\n",
    "        x_calendar_dec = self.X_calendar[enc_timesteps:, :]\n",
    "        x_last_day_sales = self.X_last_day_sales[idx].reshape(-1)\n",
    "        x_dec = np.concatenate([x_enc_dec_feats_dec, x_calendar_dec], axis=1)\n",
    "        x_dec_emb = self.X_enc_dec_feats[enc_timesteps:, idx, -num_embedding:].reshape(dec_timesteps, -1)\n",
    "        \n",
    "        if self.Y is None:\n",
    "            return [torch.from_numpy(x_enc).float(), torch.from_numpy(x_enc_emb).long(), \n",
    "                    torch.from_numpy(x_dec).float(), torch.from_numpy(x_dec_emb).long(),\n",
    "                    torch.from_numpy(x_last_day_sales).float()]\n",
    "            \n",
    "        return [torch.from_numpy(x_enc).float(), torch.from_numpy(x_enc_emb).long(),\n",
    "                torch.from_numpy(x_dec).float(), torch.from_numpy(x_dec_emb).long(),\n",
    "                torch.from_numpy(x_last_day_sales).float(), self.Y[idx, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_b = 1969 - 1 - (28*4)\n",
    "train_t_e = 1969 - 1 - (28*3)\n",
    "val_t_b = 1969 - 1 - (28*3)\n",
    "val_t_e = 1969 - 1 - (28*2)\n",
    "test_t_b = 1969 - 1 - (28*2)\n",
    "test_t_e = 1969 - 1 - (28*1)\n",
    "\n",
    "train_dataset = CustomDataset(X_prev_day_sales[:train_t_b], X_enc_only_feats[:train_t_b],\n",
    "                              X_enc_dec_feats[:train_t_e],\n",
    "                              X_calendar[:train_t_e], X_prev_day_sales[train_t_b], Y=Y[:, train_t_b:train_t_e])\n",
    "val_dataset = CustomDataset(X_prev_day_sales[:val_t_b], X_enc_only_feats[:val_t_b],\n",
    "                            X_enc_dec_feats[:val_t_e],\n",
    "                            X_calendar[:val_t_e], X_prev_day_sales[val_t_b], Y=Y[:, val_t_b:val_t_e])\n",
    "test_dataset = CustomDataset(X_prev_day_sales[:test_t_b], X_enc_only_feats[:test_t_b],\n",
    "                             X_enc_dec_feats[:test_t_e],\n",
    "                             X_calendar[:test_t_e], X_prev_day_sales[test_t_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=config.batch_size, shuffle=True, \n",
    "                                           num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a seq2seq model\n",
    "\n",
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_sizes, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(classes, hidden_size) \n",
    "                                         for classes, hidden_size in embedding_sizes])\n",
    "        self.rnn = nn.LSTM(self.input_size, config.rnn_num_hidden, \n",
    "                           config.rnn_num_layers, dropout=config.enc_rnn_dropout, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, x_emb):\n",
    "        x, x_emb = x.permute(1,0,2), x_emb.permute(1,0,2) # make time-major\n",
    "        output_emb = [emb(x_emb[:, :, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        output_emb = torch.cat(output_emb, 2)\n",
    "        \n",
    "        x_rnn = torch.cat([x, output_emb], 2)\n",
    "        \n",
    "        output, hidden = self.rnn(x_rnn)\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "# Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_sizes, output_size, config):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(classes, hidden_size) \n",
    "                                         for classes, hidden_size in embedding_sizes])\n",
    "        self.rnn = nn.LSTM(self.input_size, config.rnn_num_hidden, \n",
    "                           config.rnn_num_layers, dropout=config.dec_rnn_dropout, bidirectional=True)\n",
    "        self.pred = nn.Linear(config.rnn_num_hidden*2, output_size)\n",
    "\n",
    "    def forward(self, x, x_emb, hidden):\n",
    "        x, x_emb = x.permute(1,0,2), x_emb.permute(1,0,2) # make time-major\n",
    "        output_emb = [emb(x_emb[:, :, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        output_emb = torch.cat(output_emb, 2)\n",
    "        x_rnn = torch.cat([x, output_emb], 2)\n",
    "        \n",
    "        output, hidden = self.rnn(x_rnn, hidden)\n",
    "#         shape = output.size()\n",
    "#         output = self.pred(output.view(-1, output.size(2)))\n",
    "#         output = output.view(shape[0], shape[1]).permute(1, 0)\n",
    "        output = self.pred(output[0])\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales):\n",
    "        batch_size, pred_len = x_dec.shape[0:2]\n",
    "        \n",
    "        # create a tensor to store the outputs\n",
    "        predictions = torch.zeros(batch_size, pred_len).to(config.device)\n",
    "        \n",
    "        encoder_output, hidden = self.encoder(x_enc, x_enc_emb)\n",
    "        \n",
    "        # for each prediction timestep, use the output of the previous step, \n",
    "        # concatenated with other features as the input\n",
    "                \n",
    "        for timestep in range(0, pred_len):\n",
    "            \n",
    "            if timestep == 0:\n",
    "                # for the first timestep of decoder, use previous steps' sales\n",
    "                dec_input = torch.cat([x_dec[:, 0, :], x_last_day_sales], dim=1).unsqueeze(1)\n",
    "            else:\n",
    "                # for next timestep, current timestep's output will serve as the input along with other features\n",
    "                dec_input = torch.cat([x_dec[:, timestep, :], decoder_output], dim=1).unsqueeze(1)\n",
    "            \n",
    "            # the hidden state of the encoder will be the initialize the decoder's hidden state\n",
    "            decoder_output, hidden = self.decoder(dec_input, x_dec_emb[:, timestep, :].unsqueeze(1), hidden)\n",
    "            \n",
    "            # add predictions to predictions tensor\n",
    "            predictions[:, timestep] = decoder_output.view(-1)\n",
    "            \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    \n",
    "    # hidden dimension and no. of layers will be the same for both encoder and decoder\n",
    "    rnn_num_hidden = 256\n",
    "    rnn_num_layers = 2\n",
    "    enc_rnn_dropout = 0.0\n",
    "    dec_rnn_dropout = 0.0\n",
    "    \n",
    "    num_epochs = 10\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "config = Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embeddings): ModuleList(\n",
       "      (0): Embedding(3049, 50)\n",
       "      (1): Embedding(7, 4)\n",
       "      (2): Embedding(10, 5)\n",
       "    )\n",
       "    (rnn): LSTM(105, 256, num_layers=2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embeddings): ModuleList(\n",
       "      (0): Embedding(3049, 50)\n",
       "      (1): Embedding(7, 4)\n",
       "      (2): Embedding(10, 5)\n",
       "    )\n",
       "    (rnn): LSTM(105, 256, num_layers=2, bidirectional=True)\n",
       "    (pred): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sizes = [(3049, 50), (7, 4), (10, 5)] # for item_id, dept_id, store_id respectively\n",
    "num_features_enc = 46 + sum([j for i, j in embedding_sizes])\n",
    "num_features_dec = 46 + sum([j for i, j in embedding_sizes])\n",
    "enc = Encoder(num_features_enc, embedding_sizes, config)\n",
    "dec = Decoder(num_features_dec, embedding_sizes, 1, config)\n",
    "model = Seq2Seq(enc, dec)\n",
    "model.to(config.device)\n",
    "# writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-040dc5d0890b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loss and Optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_loss():\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for i, (x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales, y) in enumerate(notebook.tqdm(val_loader)):\n",
    "        x_enc, x_dec = Variable(x_enc).to(config.device), Variable(x_dec).to(config.device)\n",
    "        x_enc_emb, x_dec_emb = Variable(x_enc_emb).to(config.device), Variable(x_dec_emb).to(config.device)\n",
    "        x_last_day_sales = Variable(x_last_day_sales).to(config.device)\n",
    "        y = Variable(y).to(config.device)\n",
    "\n",
    "        preds = model(x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales)\n",
    "        loss = criterion(preds, y)\n",
    "        loss_iter = loss.data.cpu().numpy()\n",
    "        losses.append(loss_iter)\n",
    "\n",
    "    print('Validation Loss: %.4f' % np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8640486de104f49ab7198a17dd1af8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10], Iter [477/476] Loss: 2.3053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10457302fc68470a865b44fbca050251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.3677\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31ebd1160b04fbfa4401fb22b89d9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/10], Iter [477/476] Loss: 2.2163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e938a63e3aa4a2cb0a4252d90db336b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.2312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c216a15af34020ae3af097ce623ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/10], Iter [477/476] Loss: 2.1666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9b6395579b40c18765d57596904be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.2313\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af341d4cfb5411f881dd48c934f3f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/10], Iter [477/476] Loss: 2.1116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0723704d5c2b4cc896d65f702711cd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.1783\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0a9c6cc5be4842bdae0f5fba7eb78a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/10], Iter [477/476] Loss: 2.0902\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567ade19bd794df79d4d04066264ffdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.2125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3047de1da1444a9adbe215a8cab3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/10], Iter [477/476] Loss: 2.0432\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cee968efffc4964830e1639fc82415d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.2756\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d42651c81a43ea97befb1c84f88c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7/10], Iter [477/476] Loss: 2.0266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b07ef8a39c45e680fe6127c8d97b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.1981\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c90a465542348fb8feefbe7e5186d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8/10], Iter [477/476] Loss: 1.9879\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef8bfc50db04ce2b9afbf9770dce300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.2167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123d477ece024223ba683b54da3114e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9/10], Iter [477/476] Loss: 1.9722\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e4c29ff7f04e47b5d31528928f5222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.2564\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6377bc9a594449d8ef0c5d8dc65d24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [10/10], Iter [477/476] Loss: 1.9353\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355549ca8f5c468d8882a8d3320d33e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 2.2858\n"
     ]
    }
   ],
   "source": [
    "# Progress bar\n",
    "for epoch in range(config.num_epochs):\n",
    "    progbar = notebook.tqdm(train_loader)\n",
    "    losses = []\n",
    "    for i, (x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales, y) in enumerate(progbar):\n",
    "        model.train()\n",
    "        x_enc, x_dec = Variable(x_enc).to(config.device), Variable(x_dec).to(config.device)\n",
    "        x_enc_emb, x_dec_emb = Variable(x_enc_emb).to(config.device), Variable(x_dec_emb).to(config.device)\n",
    "        x_last_day_sales = Variable(x_last_day_sales).to(config.device)\n",
    "        y = Variable(y).to(config.device)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales)\n",
    "#         writer.add_graph(model, [x_enc, x_dec, x_last_day_sales])\n",
    "        loss = criterion(preds, y)\n",
    "        loss_iter = loss.data.cpu().numpy()\n",
    "        progbar.set_description(\"loss = %0.3f \" % np.round(loss_iter, 3))\n",
    "        losses.append(loss_iter)\n",
    "        \n",
    "        loss = torch.mean(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n",
    "           %(epoch+1, config.num_epochs, i+1, len(train_dataset)//config.batch_size, \n",
    "             np.mean(losses)))\n",
    "    get_val_loss()\n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../submissions/sub1/model.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embeddings): ModuleList(\n",
       "      (0): Embedding(3049, 50)\n",
       "      (1): Embedding(7, 4)\n",
       "      (2): Embedding(10, 5)\n",
       "    )\n",
       "    (rnn): LSTM(105, 256, num_layers=2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embeddings): ModuleList(\n",
       "      (0): Embedding(3049, 50)\n",
       "      (1): Embedding(7, 4)\n",
       "      (2): Embedding(10, 5)\n",
       "    )\n",
       "    (rnn): LSTM(105, 256, num_layers=2, bidirectional=True)\n",
       "    (pred): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../submissions/sub1/model.pth.tar'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a39362ec6f84c13abba6e4ce8114269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-1ab7ac025eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_enc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dec_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_last_day_sales\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mx_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mx_enc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dec_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_enc_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dec_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mx_last_day_sales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_last_day_sales\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for i, (x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales) in enumerate(notebook.tqdm(test_loader)):\n",
    "        x_enc, x_dec = Variable(x_enc).to(config.device), Variable(x_dec).to(config.device)\n",
    "        x_enc_emb, x_dec_emb = Variable(x_enc_emb).to(config.device), Variable(x_dec_emb).to(config.device)\n",
    "        x_last_day_sales = Variable(x_last_day_sales).to(config.device)\n",
    "\n",
    "        preds.append(model(x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales).data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.concatenate(preds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.iloc[:predictions.shape[0], 1:] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('../submissions/sub1/submission.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bb3c2cdf9b44c695f8b6d6fabed11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 1.9693\n"
     ]
    }
   ],
   "source": [
    "get_val_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>FOODS_3_823</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>FOODS_3_824</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows × 1919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id        item_id    dept_id   cat_id  \\\n",
       "0      HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "1      HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
       "2      HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
       "3      HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
       "4      HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
       "...                              ...            ...        ...      ...   \n",
       "30485    FOODS_3_823_WI_3_validation    FOODS_3_823    FOODS_3    FOODS   \n",
       "30486    FOODS_3_824_WI_3_validation    FOODS_3_824    FOODS_3    FOODS   \n",
       "30487    FOODS_3_825_WI_3_validation    FOODS_3_825    FOODS_3    FOODS   \n",
       "30488    FOODS_3_826_WI_3_validation    FOODS_3_826    FOODS_3    FOODS   \n",
       "30489    FOODS_3_827_WI_3_validation    FOODS_3_827    FOODS_3    FOODS   \n",
       "\n",
       "      store_id state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  \\\n",
       "0         CA_1       CA    0    0    0    0  ...       1       3       0   \n",
       "1         CA_1       CA    0    0    0    0  ...       0       0       0   \n",
       "2         CA_1       CA    0    0    0    0  ...       2       1       2   \n",
       "3         CA_1       CA    0    0    0    0  ...       1       0       5   \n",
       "4         CA_1       CA    0    0    0    0  ...       2       1       1   \n",
       "...        ...      ...  ...  ...  ...  ...  ...     ...     ...     ...   \n",
       "30485     WI_3       WI    0    0    2    2  ...       2       0       0   \n",
       "30486     WI_3       WI    0    0    0    0  ...       0       0       0   \n",
       "30487     WI_3       WI    0    6    0    2  ...       2       1       0   \n",
       "30488     WI_3       WI    0    0    0    0  ...       0       0       1   \n",
       "30489     WI_3       WI    0    0    0    0  ...       0       0       0   \n",
       "\n",
       "       d_1907  d_1908  d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0           1       1       1       3       0       1       1  \n",
       "1           0       0       1       0       0       0       0  \n",
       "2           1       1       1       0       1       1       1  \n",
       "3           4       1       0       1       3       7       2  \n",
       "4           0       1       1       2       2       2       4  \n",
       "...       ...     ...     ...     ...     ...     ...     ...  \n",
       "30485       0       0       0       1       0       0       1  \n",
       "30486       0       0       0       0       0       1       0  \n",
       "30487       2       0       1       0       0       1       0  \n",
       "30488       0       0       1       0       3       1       3  \n",
       "30489       0       0       0       0       0       0       0  \n",
       "\n",
       "[30490 rows x 1919 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1912, 1940)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_t_b, test_t_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1941-1914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.948881</td>\n",
       "      <td>0.818636</td>\n",
       "      <td>0.834599</td>\n",
       "      <td>0.884738</td>\n",
       "      <td>0.988404</td>\n",
       "      <td>1.120274</td>\n",
       "      <td>1.269215</td>\n",
       "      <td>1.171244</td>\n",
       "      <td>1.076180</td>\n",
       "      <td>...</td>\n",
       "      <td>1.075340</td>\n",
       "      <td>1.220519</td>\n",
       "      <td>1.376329</td>\n",
       "      <td>1.103644</td>\n",
       "      <td>0.979420</td>\n",
       "      <td>0.934300</td>\n",
       "      <td>0.943113</td>\n",
       "      <td>1.029701</td>\n",
       "      <td>1.175751</td>\n",
       "      <td>1.238253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0.667062</td>\n",
       "      <td>0.418846</td>\n",
       "      <td>0.454884</td>\n",
       "      <td>0.442493</td>\n",
       "      <td>0.471557</td>\n",
       "      <td>0.527329</td>\n",
       "      <td>0.580185</td>\n",
       "      <td>0.485661</td>\n",
       "      <td>0.440305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463578</td>\n",
       "      <td>0.565727</td>\n",
       "      <td>0.692143</td>\n",
       "      <td>0.484468</td>\n",
       "      <td>0.435793</td>\n",
       "      <td>0.441920</td>\n",
       "      <td>0.459359</td>\n",
       "      <td>0.497804</td>\n",
       "      <td>0.574895</td>\n",
       "      <td>0.581653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0.980776</td>\n",
       "      <td>0.854881</td>\n",
       "      <td>0.910752</td>\n",
       "      <td>0.979821</td>\n",
       "      <td>1.090250</td>\n",
       "      <td>1.198755</td>\n",
       "      <td>1.203921</td>\n",
       "      <td>1.045154</td>\n",
       "      <td>1.003860</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082921</td>\n",
       "      <td>1.206002</td>\n",
       "      <td>1.246968</td>\n",
       "      <td>0.972033</td>\n",
       "      <td>0.934462</td>\n",
       "      <td>0.958826</td>\n",
       "      <td>1.016848</td>\n",
       "      <td>1.128089</td>\n",
       "      <td>1.271931</td>\n",
       "      <td>1.235085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>2.781727</td>\n",
       "      <td>2.314433</td>\n",
       "      <td>2.333030</td>\n",
       "      <td>2.248819</td>\n",
       "      <td>2.350440</td>\n",
       "      <td>2.592122</td>\n",
       "      <td>2.818342</td>\n",
       "      <td>2.500714</td>\n",
       "      <td>2.382025</td>\n",
       "      <td>...</td>\n",
       "      <td>2.314852</td>\n",
       "      <td>2.642580</td>\n",
       "      <td>2.921061</td>\n",
       "      <td>2.104538</td>\n",
       "      <td>1.960665</td>\n",
       "      <td>1.912035</td>\n",
       "      <td>1.912758</td>\n",
       "      <td>2.017019</td>\n",
       "      <td>2.209183</td>\n",
       "      <td>2.143029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1.882275</td>\n",
       "      <td>1.600861</td>\n",
       "      <td>1.684266</td>\n",
       "      <td>1.818450</td>\n",
       "      <td>2.112558</td>\n",
       "      <td>2.437965</td>\n",
       "      <td>2.440682</td>\n",
       "      <td>1.948949</td>\n",
       "      <td>1.707919</td>\n",
       "      <td>...</td>\n",
       "      <td>1.813270</td>\n",
       "      <td>2.178214</td>\n",
       "      <td>2.371747</td>\n",
       "      <td>1.740101</td>\n",
       "      <td>1.583631</td>\n",
       "      <td>1.612978</td>\n",
       "      <td>1.788136</td>\n",
       "      <td>2.171239</td>\n",
       "      <td>2.618240</td>\n",
       "      <td>2.512470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60975</th>\n",
       "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60976</th>\n",
       "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60977</th>\n",
       "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60978</th>\n",
       "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60979</th>\n",
       "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60980 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id        F1        F2        F3        F4  \\\n",
       "0      HOBBIES_1_001_CA_1_validation  0.948881  0.818636  0.834599  0.884738   \n",
       "1      HOBBIES_1_002_CA_1_validation  0.667062  0.418846  0.454884  0.442493   \n",
       "2      HOBBIES_1_003_CA_1_validation  0.980776  0.854881  0.910752  0.979821   \n",
       "3      HOBBIES_1_004_CA_1_validation  2.781727  2.314433  2.333030  2.248819   \n",
       "4      HOBBIES_1_005_CA_1_validation  1.882275  1.600861  1.684266  1.818450   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "60975    FOODS_3_823_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "60976    FOODS_3_824_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "60977    FOODS_3_825_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "60978    FOODS_3_826_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "60979    FOODS_3_827_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "             F5        F6        F7        F8        F9  ...       F19  \\\n",
       "0      0.988404  1.120274  1.269215  1.171244  1.076180  ...  1.075340   \n",
       "1      0.471557  0.527329  0.580185  0.485661  0.440305  ...  0.463578   \n",
       "2      1.090250  1.198755  1.203921  1.045154  1.003860  ...  1.082921   \n",
       "3      2.350440  2.592122  2.818342  2.500714  2.382025  ...  2.314852   \n",
       "4      2.112558  2.437965  2.440682  1.948949  1.707919  ...  1.813270   \n",
       "...         ...       ...       ...       ...       ...  ...       ...   \n",
       "60975  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "60976  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "60977  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "60978  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "60979  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "\n",
       "            F20       F21       F22       F23       F24       F25       F26  \\\n",
       "0      1.220519  1.376329  1.103644  0.979420  0.934300  0.943113  1.029701   \n",
       "1      0.565727  0.692143  0.484468  0.435793  0.441920  0.459359  0.497804   \n",
       "2      1.206002  1.246968  0.972033  0.934462  0.958826  1.016848  1.128089   \n",
       "3      2.642580  2.921061  2.104538  1.960665  1.912035  1.912758  2.017019   \n",
       "4      2.178214  2.371747  1.740101  1.583631  1.612978  1.788136  2.171239   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "60975  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "60976  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "60977  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "60978  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "60979  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            F27       F28  \n",
       "0      1.175751  1.238253  \n",
       "1      0.574895  0.581653  \n",
       "2      1.271931  1.235085  \n",
       "3      2.209183  2.143029  \n",
       "4      2.618240  2.512470  \n",
       "...         ...       ...  \n",
       "60975  0.000000  0.000000  \n",
       "60976  0.000000  0.000000  \n",
       "60977  0.000000  0.000000  \n",
       "60978  0.000000  0.000000  \n",
       "60979  0.000000  0.000000  \n",
       "\n",
       "[60980 rows x 29 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff108800e97481f8204c992bdc31018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = [], []\n",
    "for i, (x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales, y) in enumerate(notebook.tqdm(val_loader)):\n",
    "        x_enc, x_dec = Variable(x_enc).to(config.device), Variable(x_dec).to(config.device)\n",
    "        x_enc_emb, x_dec_emb = Variable(x_enc_emb).to(config.device), Variable(x_dec_emb).to(config.device)\n",
    "        x_last_day_sales = Variable(x_last_day_sales).to(config.device)\n",
    "        y_true.append(y)\n",
    "\n",
    "        y_pred.append(model(x_enc, x_enc_emb, x_dec, x_dec_emb, x_last_day_sales).data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.cat(y_true, 0).data.cpu().numpy()\n",
    "y_pred = np.concatenate(y_pred, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2369509"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_true, y_pred, squared=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
