{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements for WRMSSE metric:\n",
    "* Function to convert level 12 series predictions to all level predictions by aggregating\n",
    "* Actual labels for all levels\n",
    "* Series ID as part of each DataLoader output\n",
    "* Function to create a dictionary with weights for all levels acc to series ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from tqdm import notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pickle as pkl\n",
    "from itertools import product\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../../data/sales_train_validation.csv')\n",
    "sell_prices = pd.read_csv('../../data/sell_prices.csv')\n",
    "calendar = pd.read_csv('../../data/calendar.csv')\n",
    "sample_submission = pd.read_csv('../../data/sample_submission.csv')\n",
    "weights_validation = pd.read_csv('../../data/weights_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data.pickle', 'rb') as f:\n",
    "    data_dict = pkl.load(f)\n",
    "    \n",
    "sales_data_ids = data_dict['sales_data_ids']\n",
    "calendar_index = data_dict['calendar_index']\n",
    "X_prev_day_sales = data_dict['X_prev_day_sales']\n",
    "X_enc_only_feats = data_dict['X_enc_only_feats']\n",
    "X_enc_dec_feats = data_dict['X_enc_dec_feats']\n",
    "X_calendar = data_dict['X_calendar']\n",
    "X_calendar_cols = data_dict['X_calendar_cols']\n",
    "Y = data_dict['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HOBBIES_1_001', 'HOBBIES_1', 'HOBBIES', 'CA_1', 'CA'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sales_data_ids)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all aggregated series from level 12 series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregated_series(sales, item_id, dept_id, cat_id, store_id, state_id):\n",
    "    \"\"\"\n",
    "    Aggregates 30,490 level 12 series to generate data for all 42,840 series\n",
    "    \n",
    "    Input data format:\n",
    "    sales: np array of shape (30490, num_timesteps)\n",
    "    all id arguments: np arrays of shape (30490,)\n",
    "    \"\"\"\n",
    "    \n",
    "    aggregated_series, aggregated_series_id = np.empty((42840, sales.shape[1])), np.empty(42840, '<U28')\n",
    "    \n",
    "    # Level 1\n",
    "    aggregated_series[0] = sales.sum(0)\n",
    "    aggregated_series_id[0] = 'Level1_Total_X'\n",
    "    fill_id = 1\n",
    "    \n",
    "    # Level 2\n",
    "    for agg_element in np.unique(state_id):\n",
    "        agg_sales = sales[np.where(state_id == agg_element)[0]].sum(0)[np.newaxis, :]\n",
    "        aggregated_series[fill_id] = agg_sales\n",
    "        aggregated_series_id[fill_id] = f'Level2_{agg_element}_X'\n",
    "        fill_id += 1\n",
    "        \n",
    "    # Level 3\n",
    "    for agg_element in np.unique(store_id):\n",
    "        agg_sales = sales[np.where(store_id == agg_element)[0]].sum(0)[np.newaxis, :]\n",
    "        aggregated_series[fill_id] = agg_sales\n",
    "        aggregated_series_id[fill_id] = f'Level3_{agg_element}_X'\n",
    "        fill_id += 1\n",
    "\n",
    "        \n",
    "    # Level 4\n",
    "    for agg_element in np.unique(cat_id):\n",
    "        agg_sales = sales[np.where(cat_id == agg_element)[0]].sum(0)[np.newaxis, :]\n",
    "        aggregated_series[fill_id] = agg_sales\n",
    "        aggregated_series_id[fill_id] = f'Level4_{agg_element}_X'\n",
    "        fill_id += 1\n",
    "        \n",
    "    # Level 5\n",
    "    for agg_element in np.unique(dept_id):\n",
    "        agg_sales = sales[np.where(dept_id == agg_element)[0]].sum(0)[np.newaxis, :]\n",
    "        aggregated_series[fill_id] = agg_sales\n",
    "        aggregated_series_id[fill_id] = f'Level5_{agg_element}_X'\n",
    "        fill_id += 1\n",
    "    \n",
    "    # Level 6\n",
    "    for agg_1, agg_2 in product(np.unique(state_id), np.unique(cat_id)):\n",
    "        agg_sales = sales[np.where((state_id == agg_1) & (cat_id == agg_2))[0]].sum(0)[np.newaxis, :]\n",
    "        aggregated_series[fill_id] = agg_sales\n",
    "        aggregated_series_id[fill_id] = f'Level6_{agg_1}_{agg_2}'\n",
    "        fill_id += 1\n",
    "    \n",
    "    # Level 7\n",
    "    for agg_1, agg_2 in product(np.unique(state_id), np.unique(dept_id)):\n",
    "        agg_sales = sales[np.where((state_id == agg_1) & (dept_id == agg_2))[0]].sum(0)[np.newaxis, :]\n",
    "        aggregated_series[fill_id] = agg_sales\n",
    "        aggregated_series_id[fill_id] = f'Level7_{agg_1}_{agg_2}'\n",
    "        fill_id += 1\n",
    "        \n",
    "    # Level 8\n",
    "    for agg_1, agg_2 in product(np.unique(store_id), np.unique(cat_id)):\n",
    "        agg_sales = sales[np.where((store_id == agg_1) & (cat_id == agg_2))[0]].sum(0)[np.newaxis, :]\n",
    "        aggregated_series[fill_id] = agg_sales\n",
    "        aggregated_series_id[fill_id] = f'Level8_{agg_1}_{agg_2}'\n",
    "        fill_id += 1\n",
    "    \n",
    "    # Level 9\n",
    "    for agg_1, agg_2 in product(np.unique(store_id), np.unique(dept_id)):\n",
    "        agg_sales = sales[np.where((store_id == agg_1) & (dept_id == agg_2))[0]].sum(0)[np.newaxis, :]\n",
    "        aggregated_series[fill_id] = agg_sales\n",
    "        aggregated_series_id[fill_id] = f'Level9_{agg_1}_{agg_2}'\n",
    "        fill_id += 1\n",
    "        \n",
    "    # Level 10\n",
    "    for agg_element in np.unique(item_id):\n",
    "        agg_sales = sales[np.where(item_id == agg_element)[0]].sum(0)[np.newaxis, :]\n",
    "        aggregated_series[fill_id] = agg_sales\n",
    "        aggregated_series_id[fill_id] = f'Level10_{agg_element}_X'\n",
    "        fill_id += 1\n",
    "    \n",
    "    # Level 11\n",
    "    for agg_1, agg_2 in product(np.unique(state_id), np.unique(item_id)):\n",
    "        agg_sales = sales[np.where((state_id == agg_1) & (item_id == agg_2))[0]].sum(0)[np.newaxis, :]\n",
    "        aggregated_series[fill_id] = agg_sales\n",
    "        aggregated_series_id[fill_id] = f'Level11_{agg_1}_{agg_2}'\n",
    "        fill_id += 1\n",
    "        \n",
    "    # Level 12\n",
    "    aggregated_series[fill_id:] = sales\n",
    "    aggregated_series_id[fill_id:] = np.array([f'Level12_{item}_{store}' \n",
    "                                               for item, store in zip(item_id, store_id)])\n",
    "    \n",
    "    # Return the arrays sorted acc to ids\n",
    "    sort_idx = aggregated_series_id.argsort()\n",
    "    \n",
    "    return aggregated_series[sort_idx], aggregated_series_id[sort_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_series, agg_series_id = get_aggregated_series(Y, *[sales_data_ids[:, i] for i in range(0, 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate weights for 42,840 series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_all_levels(sales, sell_price, item_id, dept_id, cat_id, store_id, state_id):\n",
    "    \"\"\"\n",
    "    Generates weights for all 42,840 series\n",
    "    \n",
    "    Input data format:\n",
    "    sales: np array of shape (30490, 28)\n",
    "    sell_price: np array of shape (30490, 28)\n",
    "    \n",
    "    all id arguments: np arrays of shape (30490,)\n",
    "    \"\"\"\n",
    "    \n",
    "    assert (sales.shape == sell_price.shape), \"Sell price and Sales arrays have different sizes\"\n",
    "    assert (sales.shape[1] == 28), \"Number of timesteps provided weight calculation is not equal to 28\"\n",
    "    \n",
    "    # Get actual dollar sales for last 28 days for all 42,840 series\n",
    "    dollar_sales = sales * sell_price\n",
    "    agg_series, agg_series_id = get_aggregated_series(dollar_sales, item_id, dept_id, cat_id, store_id, state_id)\n",
    "    \n",
    "    # Sum up the actual dollar sales for all 28 timesteps\n",
    "    agg_series = agg_series.sum(1)\n",
    "    \n",
    "    # Calculate total sales for each level\n",
    "    level_totals = agg_series[np.core.defchararray.find(agg_series_id, f'Level1_') == 0].sum()\n",
    "    \n",
    "    # Calculate weight for each series\n",
    "    weights = agg_series / level_totals\n",
    "    \n",
    "    return weights, agg_series_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.25 s ± 57.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "weights, agg_series_id = get_weights_all_levels(Y[:, -84:-56], X_enc_dec_feats[:, :, 0].T[:, -84:-56], \n",
    "                                 *[sales_data_ids[:, i] for i in range(0, 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_validation = pd.read_csv('../../data/weights_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.DataFrame({'id': agg_series_id, 'my_weight': weights})\n",
    "\n",
    "weights_validation['id'] = weights_validation['Level_id'] + '_' \\\n",
    "                            + weights_validation['Agg_Level_1'] + '_' + weights_validation['Agg_Level_2']\n",
    "weights_validation = weights_validation.merge(right=weights, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(((weights_validation.Weight - weights_validation.my_weight).values < 1e-7) != True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DISCARDED: Calculate weights for 30,490 series by adding upper level weights to level 12 weights according to hierarchy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level_id</th>\n",
       "      <th>Agg_Level_1</th>\n",
       "      <th>Agg_Level_2</th>\n",
       "      <th>Weight</th>\n",
       "      <th>id</th>\n",
       "      <th>my_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Level1_Total_X</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Level2</td>\n",
       "      <td>CA</td>\n",
       "      <td>X</td>\n",
       "      <td>0.442371</td>\n",
       "      <td>Level2_CA_X</td>\n",
       "      <td>0.442371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Level2</td>\n",
       "      <td>TX</td>\n",
       "      <td>X</td>\n",
       "      <td>0.269297</td>\n",
       "      <td>Level2_TX_X</td>\n",
       "      <td>0.269297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Level2</td>\n",
       "      <td>WI</td>\n",
       "      <td>X</td>\n",
       "      <td>0.288332</td>\n",
       "      <td>Level2_WI_X</td>\n",
       "      <td>0.288332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Level3</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>X</td>\n",
       "      <td>0.110888</td>\n",
       "      <td>Level3_CA_1_X</td>\n",
       "      <td>0.110888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42835</th>\n",
       "      <td>Level12</td>\n",
       "      <td>HOUSEHOLD_2_516</td>\n",
       "      <td>TX_2</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>Level12_HOUSEHOLD_2_516_TX_2</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42836</th>\n",
       "      <td>Level12</td>\n",
       "      <td>HOUSEHOLD_2_516</td>\n",
       "      <td>TX_3</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>Level12_HOUSEHOLD_2_516_TX_3</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42837</th>\n",
       "      <td>Level12</td>\n",
       "      <td>HOUSEHOLD_2_516</td>\n",
       "      <td>WI_1</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>Level12_HOUSEHOLD_2_516_WI_1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42838</th>\n",
       "      <td>Level12</td>\n",
       "      <td>HOUSEHOLD_2_516</td>\n",
       "      <td>WI_2</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>Level12_HOUSEHOLD_2_516_WI_2</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42839</th>\n",
       "      <td>Level12</td>\n",
       "      <td>HOUSEHOLD_2_516</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Level12_HOUSEHOLD_2_516_WI_3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42840 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Level_id      Agg_Level_1 Agg_Level_2    Weight  \\\n",
       "0       Level1            Total           X  1.000000   \n",
       "1       Level2               CA           X  0.442371   \n",
       "2       Level2               TX           X  0.269297   \n",
       "3       Level2               WI           X  0.288332   \n",
       "4       Level3             CA_1           X  0.110888   \n",
       "...        ...              ...         ...       ...   \n",
       "42835  Level12  HOUSEHOLD_2_516        TX_2  0.000013   \n",
       "42836  Level12  HOUSEHOLD_2_516        TX_3  0.000008   \n",
       "42837  Level12  HOUSEHOLD_2_516        WI_1  0.000002   \n",
       "42838  Level12  HOUSEHOLD_2_516        WI_2  0.000002   \n",
       "42839  Level12  HOUSEHOLD_2_516        WI_3  0.000000   \n",
       "\n",
       "                                 id  my_weight  \n",
       "0                    Level1_Total_X   1.000000  \n",
       "1                       Level2_CA_X   0.442371  \n",
       "2                       Level2_TX_X   0.269297  \n",
       "3                       Level2_WI_X   0.288332  \n",
       "4                     Level3_CA_1_X   0.110888  \n",
       "...                             ...        ...  \n",
       "42835  Level12_HOUSEHOLD_2_516_TX_2   0.000013  \n",
       "42836  Level12_HOUSEHOLD_2_516_TX_3   0.000008  \n",
       "42837  Level12_HOUSEHOLD_2_516_WI_1   0.000002  \n",
       "42838  Level12_HOUSEHOLD_2_516_WI_2   0.000002  \n",
       "42839  Level12_HOUSEHOLD_2_516_WI_3   0.000000  \n",
       "\n",
       "[42840 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_act_prev, B_act_prev = 7, 17\n",
    "Total_act_prev = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_act, B_act = 10, 15\n",
    "Total_act = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pred, B_pred = 8, 12\n",
    "Total_pred = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7083333333333335"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WRMSE_level_2 = ((2) * (7/24)) + ((3) * (17/24))\n",
    "WRMSE_level_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WRMSE_level_1 = (5) * (1)\n",
    "WRMSE_level_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.854166666666667"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WRMSE_total = (WRMSE_level_1 + WRMSE_level_2) / 2\n",
    "WRMSE_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pred, B_pred = 8, 18\n",
    "Total_pred = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7083333333333335"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WRMSE_level_2 = ((2) * (7/24)) + ((3) * (17/24))\n",
    "WRMSE_level_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WRMSE_level_1 = (1) * (1)\n",
    "WRMSE_level_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8541666666666667"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WRMSE_total = (WRMSE_level_1 + WRMSE_level_2) / 2\n",
    "WRMSE_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.479793004911743e-06"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_validation.iloc[-3]['Weight'] / weights_validation.iloc[3]['Weight'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_modified_level_12(sales, sell_price, item_id, dept_id, cat_id, store_id, state_id):\n",
    "    \"\"\"\n",
    "    Generates weights for for 30,490 series by adding upper level\n",
    "    weights to level 12 weights according to the hierarchy \n",
    "    \n",
    "    Input data format:\n",
    "    sales: np array of shape (30490, 28)\n",
    "    sell_price: np array of shape (30490, 28)\n",
    "    \n",
    "    all id arguments: np arrays of shape (30490,)\n",
    "    \"\"\"\n",
    "    \n",
    "    assert (sales.shape == sell_price.shape), \"Sell price and Sales arrays have different sizes\"\n",
    "    assert (sales.shape[1] == 28), \"Number of timesteps provided weight calculation is not equal to 28\"\n",
    "    \n",
    "    # Get actual dollar sales for last 28 days for all 42,840 series\n",
    "    dollar_sales = sales * sell_price\n",
    "    agg_series, agg_series_id = get_aggregated_series(dollar_sales, item_id, dept_id, cat_id, store_id, state_id)\n",
    "    \n",
    "    # Sum up the actual dollar sales for all 28 timesteps\n",
    "    agg_series = agg_series.sum(1)\n",
    "    \n",
    "    \n",
    "    # Get sales contribution of each level 12 series to its upper hierarchical series\n",
    "    # and add the upper level series' weights to the corresponding level 12 series in the same ratio\n",
    "    \n",
    "    weights_dict = {}\n",
    "    for series_sales, series in zip(agg_series, agg_series_id):\n",
    "        \n",
    "        \n",
    "    # Level 1\n",
    "    aggregated_series[0] = sales.sum(0)\n",
    "    aggregated_series_id[0] = 'Level1_Total_X'\n",
    "    fill_id = 1\n",
    "    \n",
    "    # Level 2\n",
    "    for agg_element in np.unique(state_id):\n",
    "        agg_sales = sales[np.where(state_id == agg_element)[0]].sum(0)[np.newaxis, :]\n",
    "        aggregated_series[fill_id] = agg_sales\n",
    "        aggregated_series_id[fill_id] = f'Level2_{agg_element}_X'\n",
    "        fill_id += 1\n",
    "    \n",
    "    # Calculate total sales for each level\n",
    "    level_totals = {}\n",
    "    for level in range(1, 13):\n",
    "        level_totals[level] = agg_series[np.core.defchararray.find(agg_series_id, f'Level{level}_') == 0].sum()\n",
    "    \n",
    "    # Calculate weight for each series\n",
    "    weights_dict = {}\n",
    "    for series_sales, series in zip(agg_series, agg_series_id):\n",
    "        level = int(series[series.find('Level') + 5: series.find('_')])\n",
    "        weights_dict[series] = (series_sales / level_totals[level])\n",
    "    \n",
    "    return weights_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
